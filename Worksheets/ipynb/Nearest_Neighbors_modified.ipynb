{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and test a Nearest Neighbors classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Iris data to use for experiments. The data include 50 observations of each of 3 types of irises (150 total). Each observation includes 4 measurements: sepal and petal width and height. The goal is to predict the iris type from these measurements.\n",
    "\n",
    "<http://en.wikipedia.org/wiki/Iris_flower_data_set>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris target names: ['setosa' 'versicolor' 'virginica']\n",
      "Iris feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# Load the data, which is included in sklearn.\n",
    "iris = load_iris()\n",
    "print 'Iris target names:', iris.target_names\n",
    "print 'Iris feature names:', iris.feature_names\n",
    "X, Y = iris.data, iris.target\n",
    "\n",
    "# Shuffle the data, but make sure that the features and accompanying labels stay in sync.\n",
    "np.random.seed(0)  #  To ensure repeatability of results\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "# Split into train and test.\n",
    "train_data, train_labels = X[:100], Y[:100]\n",
    "test_data, test_labels = X[100:], Y[100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a distance function that returns the distance between 2 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##  Note: the assumption is len (v1) == len (v2)\n",
    "def EuclideanDistance(v1, v2):\n",
    "    sum = 0.0\n",
    "    for index in range(len(v1)):\n",
    "        sum += (v1[index] - v2[index]) ** 2\n",
    "    return sum ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just an example of code for Euclidean distance.  In order to create a robust production-quality code, you have to be prepared for situations where len(v1) != len (v2): missing data; bad data; wrong data types, etc.  Make sure your functions are always prepared for such scenarios: as much as 50% of a data scientists' job is cleaning up the data.  A great overview of \"what can go wrong with data\" is, e.g., in this book:  http://www.amazon.com/Bad-Data-Handbook-Cleaning-Back/dp/1449321887.\n",
    "\n",
    "Just for fun, let's compute all the pairwise distances in the training data and plot a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEACAYAAABMEua6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEcZJREFUeJzt3X+s3XV9x/HnCyoi6KxM05a2iyTCYpMtgrMzOme3IUHj\nCn/xI9kkjvkP88eyaGzNIt0//vpjarLwjwqpTLp0OAjGZbYgd+o/IApDKRUwa8Zl9oJOiUpmILz3\nx/12HAvt+XXv/d7zuc9HctLvr8/5vs+9t6/zOZ/zOd+TqkKS1IZT+i5AkrR0DHVJaoihLkkNMdQl\nqSGGuiQ1xFCXpIaMFOpJ1ie5OcmDSQ4l+f0kZyU5mOShJAeSrB84fneSh5McTnLR8pUvSRo0ak/9\ns8C/VtVrgd8FDgO7gINVdR5wR7dOkm3A5cA24GLguiS+IpCkFTA0bJO8HHhLVV0PUFXPVNWTwE5g\nb3fYXuDSbvkSYF9VPV1VR4BHgO1LXbgk6flG6UGfAzyR5IYk303yuSRnAhuqaqE7ZgHY0C2fDcwP\ntJ8HNi9ZxZKkExol1NcBFwDXVdUFwC/phlqOqcVrDZzsegNei0CSVsC6EY6ZB+ar6tvd+s3AbuBo\nko1VdTTJJuDxbv9jwNaB9lu6bf8viSEvSROoqpxsf0a5oFeSbwB/WVUPJdkDnNHt+klVfTLJLmB9\nVe3q3ii9icVx9M3A7cBrauBESWpYYatZkj1VtafvOiZl/f2Z5drB+vs2SnaO0lMHeB/wpSSnAT8E\n3g2cCuxPcjVwBLgMoKoOJdkPHAKeAa6pUZ45ejLpq4Yk18LwZ01JWkkjhXpV/QfwhhfYdeEJjv8Y\n8LEp6lph4+b6nu5mnktaXZw/PpEdfRcwrbm+C5jSXN8FTGGu7wKmNNd3AVOa67uA5TbSmPqSn3QV\njakvDr9M+jOIwy+SVswo2WlPXZIaYqhLUkMMdUlqiKEuSQ0x1CWpIYa6JDXEUJekhhjqktQQQ12S\nGmKoS1JDDHVJaoihLkkNMdQlqSGGuiQ1xFCXpIYY6pLUkFG/o3RVm/R7RiWpNU2E+qLJv71Iklrh\n8IskNcRQl6SGGOqS1BBDXZIaYqhLUkMMdUlqiKEuSQ0x1CWpISOFepIjSe5Pcm+Su7ttZyU5mOSh\nJAeSrB84fneSh5McTnLRchUvSfp1o/bUC9hRVedX1fZu2y7gYFWdB9zRrZNkG3A5sA24GLguia8I\nJGkFjBO2x3+efiewt1veC1zaLV8C7Kuqp6vqCPAIsB1J0rIbp6d+e5J7kryn27ahqha65QVgQ7d8\nNjA/0HYe2Dx1pZKkoUa9oNebq+pHSV4FHExyeHBnVdWQKyV6FUVJWgEjhXpV/aj794kkt7A4nLKQ\nZGNVHU2yCXi8O/wxYOtA8y3dtl+TZM/A6lxVzY1fviS1K8kOYMdYbapO3olOcgZwalX9PMmZwAHg\n74ALgZ9U1SeT7ALWV9Wu7o3Sm1gM/s3A7cBrauBESaqqluyat4uvEqa59G5/l+1dyp+DpLaNkp2j\n9NQ3ALckOXb8l6rqQJJ7gP1JrgaOAJcBVNWhJPuBQ8AzwDU17Jljpk3z0MxzSUtraE99WU7aVE99\nulC3py5pVKNkp/PHJakhhrokNcRQl6SGGOqS1BBDXZIaYqhLUkMMdUlqiKEuSQ0x1CWpIYa6JDXE\nUJekhhjqktQQQ12SGmKoS1JDDHVJaoihLkkNMdQlqSGGuiQ1xFCXpIYY6pLUEENdkhpiqEtSQwx1\nSWqIoS5JDTHUJakhhrokNcRQl6SGGOqS1BBDXZIaMlKoJzk1yb1JvtKtn5XkYJKHkhxIsn7g2N1J\nHk5yOMlFy1W4JOn5Ru2pfwA4BFS3vgs4WFXnAXd06yTZBlwObAMuBq5L4qsBSVohQwM3yRbgHcDn\ngXSbdwJ7u+W9wKXd8iXAvqp6uqqOAI8A25eyYEnSiY3Si/408CHg2YFtG6pqoVteADZ0y2cD8wPH\nzQObpy1SkjSadSfbmeSdwONVdW+SHS90TFVVknqhfccOOcF97xlYnauquZOXKklrS5e7O8Zpc9JQ\nB94E7EzyDuB04DeS3AgsJNlYVUeTbAIe745/DNg60H5Lt+15qmrPOIVK0lrTdXbnjq0nuXZYm5MO\nv1TVR6pqa1WdA1wBfL2q/hy4DbiqO+wq4NZu+TbgiiSnJTkHOBe4e8zHIUma0LCe+vGODaV8Atif\n5GrgCHAZQFUdSrKfxZkyzwDXVNXJhmYkSUsofWRukqqqDD9y9Ps7wdD9KK3pp+1i+6X8OUhq2yjZ\n6RxySWqIoS5JDTHUJakhhrokNcRQl6SGGOqS1BBDXZIaMu6Hj7TEhlw356Sc4y7peIZ676b54JMk\n/TqHXySpIYa6JDXEUJekhhjqktQQQ12SGmKoS1JDDHVJaoihLkkNMdQlqSGGuiQ1xFCXpIYY6pLU\nEENdkhpiqEtSQwx1SWqIoS5JDTHUJakhhrokNcRQl6SGnDTUk5ye5K4k9yU5lOTj3fazkhxM8lCS\nA0nWD7TZneThJIeTXLTcD0CS9JxUnfyLj5OcUVVPJVkHfAv4ILAT+HFVfSrJh4FXVNWuJNuAm4A3\nAJuB24HzqurZ4+6zqmrJvjk5SU33Bc59tJ3+3Ev5M5S0+o2SnUOHX6rqqW7xNOBU4Kcshvrebvte\n4NJu+RJgX1U9XVVHgEeA7eOXLrUhSU1z67t+zZ6hoZ7klCT3AQvAnVX1ALChqha6QxaADd3y2cD8\nQPN5Fnvs0hpWE96k8a0bdkA3dPK6JC8Hvpbkj47bP6xH8YL7kuwZWJ2rqrnh5UrS2pFkB7BjnDZD\nQ/2YqnoyyVeB1wMLSTZW1dEkm4DHu8MeA7YONNvSbXuh+9szTqGStNZ0nd25Y+tJrh3WZtjsl1ce\nm9mS5CXA24B7gduAq7rDrgJu7ZZvA65IclqSc4BzgbvHehSSpIkN66lvAvYmOYXFJ4Abq+qOJPcC\n+5NcDRwBLgOoqkNJ9gOHgGeAa2rY9BpJ0pIZOqVxWU7qlMYlObdTGle/af82/R1r0JJMaZQkzQ5D\nXZIaYqhLUkMMdUlqiKEuSQ0x1CWpIYa6JDXEUJekhhjqktSQkS/oJa1VXtdcs8RQl0YyzaUkpJVj\nqGsmTNtb9hoqWisMdc0Qe8vSMIa61gTHxbVWGOpaI6a9RLI0G5zSKEkNsac+w6YZUvCNQ6lNhvpM\n843D1vnErXEZ6tKq5hO3xuOYuiQ1xFCXpIYY6pLUEENdkhpiqEtSQwx1SWqIoS5JDXGeutQoP7i0\nNhnqWjFeKXGl+cGltWjo8EuSrUnuTPJAku8neX+3/awkB5M8lORAkvUDbXYneTjJ4SQXLecD0Kyp\nCW+SRpGqk/+HSbIR2FhV9yV5KfAd4FLg3cCPq+pTST4MvKKqdiXZBtwEvAHYDNwOnFdVzw7cZy3l\ny7vFHuA0vZI+2vZ57vTy8trf0+y0dfhldRolO4f21KvqaFXd1y3/AniQxbDeCeztDtvLYtADXALs\nq6qnq+oI8AiwfaJHIEkay1izX5K8GjgfuAvYUFUL3a4FYEO3fDYwP9BsnsUnAUnSMhv5jdJu6OXL\nwAeq6ufJc68AqqqGvAn2vH1J9gyszlXV3Ki1aHrOjJBWvyQ7gB3jtBkp1JO8iMVAv7Gqbu02LyTZ\nWFVHk2wCHu+2PwZsHWi+pdv2a6pqzziFaqk5M0Ja7brO7tyx9STXDmszyuyXAF8ADlXVZwZ23QZc\n1S1fBdw6sP2KJKclOQc4F7h7hPolrRJJatJb37WvdaPMfvkD4BvA/TzXvdvNYlDvB34LOAJcVlU/\n69p8BPgL4BkWh2u+dtx9Ovul13P3MzPC39PaaOvw3PIZJTuHhvpyMNT7PrehPhvnns22hvryWZIp\njZKk2WGoS1JDDHVJaoihLkkNMdQlqSGGuiQ1ZFVcTz3JVuBVfdchSbNuVYQ6vORv4cx3wfpfjd/2\nZy+GHy99SZI0g1ZJqK87Fa49Hd57+vhtPwv89ZJXJEmzaJWEumaJ1/eQVi9DXRPwCo/SauXsF0lq\niKEuSQ0x1CWpIYa6JDXEUJekhhjqktQQQ12SGmKoS1JDDHVJaoihLkkNMdQlqSGGuiQ1xFCXpIZ4\nlUZJS2qaSzNXlZfynJKhLmmJeWnmPjn8IkkNMdQlqSFDQz3J9UkWknxvYNtZSQ4meSjJgSTrB/bt\nTvJwksNJLlquwiVJzzdKT/0G4OLjtu0CDlbVecAd3TpJtgGXA9u6Ntcl8dWAJK2QoYFbVd8Efnrc\n5p3A3m55L3Bpt3wJsK+qnq6qI8AjwPalKVWSNMykvegNVbXQLS8AG7rls4H5gePmgc0TnkOSNKap\nh0aqqjj5HKaJ56xKksYz6Tz1hSQbq+pokk3A4932x4CtA8dt6bY9T5I9z62dvmnCOiSpWUl2ADvG\naTNpqN8GXAV8svv31oHtNyX5exaHXc4F7n6hO6iqPceWk9/4/IR1SFKzqmoOmDu2nuTaYW2GhnqS\nfcBbgVcmeRT4KPAJYH+Sq4EjwGVdAYeS7AcOAc8A13TDM5KkFTA01KvqyhPsuvAEx38M+Ng0RUmS\nJuMccklqiKEuSQ0x1CWpIYa6JDXEUJekhhjqktQQQ12SGuLX2UlaNab5flPwO07BUJe0qkyT6Ws+\nzwGHXySpKYa6JDXEUJekhhjqktQQQ12SGmKoS1JDDHVJaoihLkkNMdQlqSGGuiQ1xFCXpIYY6pLU\nEENdkhpiqEtSQ7z0rqRmTHM99lauxW6oS2rIpJneRJ4DDr9IUlMMdUlqiKEuSQ1ZllBPcnGSw0ke\nTvLh5TiHJOn5ljzUk5wK/ANwMbANuDLJa5f6PP2a67uANW6u7wKmMNd3AVOa67uAKc31XcCyW46e\n+nbgkao6UlVPA/8EXLIM5+nRXN8FrHFzfRcwhbm+C5jSXN8FTGnuhHuS1KS3lat/uOUI9c3AowPr\n8902SVrFasLb6rIc89QneJTPPguf/V/4l1+N3/a/XgycPn47SWpPqpb2mSbJG4E9VXVxt74beLaq\nPjlwzOp7epOkGTDsk6/LEerrgB8AfwL8N3A3cGVVPbikJ5IkPc+SD79U1TNJ3gt8DTgV+IKBLkkr\nY8l76pKk/qz4J0pn+YNJSa5PspDke33XMq4kW5PcmeSBJN9P8v6+axpHktOT3JXkviSHkny875om\nkeTUJPcm+UrftYwryZEk93f13913PeNKsj7JzUke7P6G3th3TaNK8tvdz/3Y7ckT/R9e0Z5698Gk\nHwAXAo8B32aGxtuTvAX4BfDFqvqdvusZR5KNwMaqui/JS4HvAJfOys8eIMkZVfVU977Nt4APVtW3\n+q5rHEn+Bng98LKq2tl3PeNI8p/A66vqf/quZRJJ9gL/XlXXd39DZ1bVk33XNa4kp7CYn9ur6tHj\n9690T32mP5hUVd8Eftp3HZOoqqNVdV+3/AvgQeDsfqsaT1U91S2exuL7NTMVLkm2AO8APs/sXut1\nJutO8nLgLVV1PSy+9zeLgd65EPjhCwU6rHyo+8GkVSDJq4Hzgbv6rWQ8SU5Jch+wANxZVYf6rmlM\nnwY+BDzbdyETKuD2JPckeU/fxYzpHOCJJDck+W6SzyU5o++iJnQFcNOJdq50qPuubM+6oZebgQ90\nPfaZUVXPVtXrgC3AHybZ0XNJI0vyTuDxqrqXGe3tAm+uqvOBtwN/1Q1Hzop1wAXAdVV1AfBLYFe/\nJY0vyWnAnwL/fKJjVjrUHwO2DqxvZbG3rhWQ5EXAl4F/rKpb+65nUt3L5q8Cv9d3LWN4E7CzG5fe\nB/xxki/2XNNYqupH3b9PALewOJw6K+aB+ar6drd+M4shP2veDnyn+x28oJUO9XuAc5O8unvGuRy4\nbYVrWJOSBPgCcKiqPtN3PeNK8sok67vllwBvA+7tt6rRVdVHqmprVZ3D4svnr1fVu/qua1RJzkjy\nsm75TOAiYGZmgVXVUeDRJOd1my4EHuixpEldyWKn4IRW9DtKZ/2DSUn2AW8FfjPJo8BHq+qGnssa\n1ZuBPwPuT3IsDHdX1b/1WNM4NgF7u3f+TwFurKo7eq5pGrM2FLkBuGWxb8A64EtVdaDfksb2PuBL\nXYfyh8C7e65nLN2T6YXASd/P8MNHktQQv85OkhpiqEtSQwx1SWqIoS5JDTHUJakhhrokNcRQl6SG\nGOqS1JD/Ay69pyxzUgFcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1565a9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dists = []\n",
    "for i in range(len(train_data) - 1):\n",
    "    for j in range(i + 1, len(train_data)):\n",
    "        dist = EuclideanDistance(train_data[i], train_data[j])\n",
    "        dists.append(dist)\n",
    "        \n",
    "fig = plt.hist(dists, 20) ## Play with different values of the parameter; see how the view changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok now let's create a class that implements a Nearest Neighbors classifier. We'll model it after the sklearn classifier implementations, with fit() and predict() methods.\n",
    "\n",
    "<http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NearestNeighbors:\n",
    "    # Initialize an instance of the class.\n",
    "    def __init__(self, metric=EuclideanDistance):\n",
    "        self.metric = metric\n",
    "    \n",
    "    # No training for Nearest Neighbors. Just store the data.\n",
    "    def fit(self, train_data, train_labels):\n",
    "        self.train_data = train_data\n",
    "        self.train_labels = train_labels\n",
    "    \n",
    "    # Make predictions for each test example and return results.\n",
    "    def predict(self, test_data):\n",
    "        results = []\n",
    "        for item in test_data:\n",
    "            results.append(self._predict_item(item))\n",
    "        return results\n",
    "    \n",
    "    # Private function for making a single prediction.\n",
    "    def _predict_item(self, item):\n",
    "        best_dist, best_label = 1.0e10, None\n",
    "        for i in range(len(self.train_data)):\n",
    "            dist = self.metric(self.train_data[i], item)\n",
    "           # print i, dist, best_dist, best_label, self.train_labels[i]\n",
    "            if dist < best_dist:\n",
    "                best_label = self.train_labels[i]\n",
    "                best_dist = dist\n",
    "        return best_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run an experiment with the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  50  correct:  48  accuracy: 96.00\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "clf = NearestNeighbors(metric = EuclideanDistance)\n",
    "clf.fit(train_data, train_labels)\n",
    "preds = clf.predict(test_data)\n",
    "\n",
    "correct, total = 0, 0\n",
    "for pred, label in zip(preds, test_labels):\n",
    "    if pred == label: correct += 1\n",
    "    total += 1\n",
    "    \n",
    "accuracy = 1.0*correct/total\n",
    "accuracy_pct = 100.0*correct/total\n",
    "\n",
    "print 'total: %3d  correct: %3d  accuracy: %3.2f' %(total, correct, accuracy_pct)\n",
    "print pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and see what happens if we do not set the seed for the random number generator.  When no seed is given, RNG usually sets the seed to the numeric interpretation of UTC (Coordinated Universal Time).  Let us do just that (change the second argument in range() function before you run this loop):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143226146398\n",
      "seed: 1432261463 total:  50  correct:  49  accuracy: 0.98\n",
      "seed: 1432261464 total:  50  correct:  49  accuracy: 0.98\n",
      "seed: 1432261465 total:  50  correct:  49  accuracy: 0.98\n",
      "seed: 1432261466 total:  50  correct:  48  accuracy: 0.96\n",
      "seed: 1432261467 total:  50  correct:  48  accuracy: 0.96\n",
      "seed: 1432261468 total:  50  correct:  46  accuracy: 0.92\n",
      "seed: 1432261469 total:  50  correct:  47  accuracy: 0.94\n",
      "seed: 1432261470 total:  50  correct:  47  accuracy: 0.94\n",
      "seed: 1432261471 total:  50  correct:  48  accuracy: 0.96\n",
      "seed: 1432261472 total:  50  correct:  49  accuracy: 0.98\n",
      "seed: 1432261473 total:  50  correct:  47  accuracy: 0.94\n",
      "seed: 1432261474 total:  50  correct:  48  accuracy: 0.96\n",
      "seed: 1432261475 total:  50  correct:  49  accuracy: 0.98\n",
      "seed: 1432261476 total:  50  correct:  47  accuracy: 0.94\n",
      "seed: 1432261477 total:  50  correct:  48  accuracy: 0.96\n",
      "seed: 1432261478 total:  50  correct:  47  accuracy: 0.94\n",
      "seed: 1432261479 total:  50  correct:  47  accuracy: 0.94\n",
      "seed: 1432261480 total:  50  correct:  48  accuracy: 0.96\n",
      "seed: 1432261481 total:  50  correct:  47  accuracy: 0.94\n",
      "seed: 1432261482 total:  50  correct:  48  accuracy: 0.96\n",
      "seed: 1432261483 total:  50  correct:  49  accuracy: 0.98\n",
      "seed: 1432261484 total:  50  correct:  48  accuracy: 0.96\n",
      "seed: 1432261485 total:  50  correct:  47  accuracy: 0.94\n",
      "seed: 1432261486 total:  50  correct:  48  accuracy: 0.96\n",
      "seed: 1432261487 total:  50  correct:  47  accuracy: 0.94\n",
      "seed: 1432261488 total:  50  correct:  46  accuracy: 0.92\n",
      "seed: 1432261489 total:  50  correct:  48  accuracy: 0.96\n",
      "seed: 1432261490 total:  50  correct:  49  accuracy: 0.98\n",
      "seed: 1432261491 total:  50  correct:  48  accuracy: 0.96\n",
      "seed: 1432261492 total:  50  correct:  46  accuracy: 0.92\n",
      "seed: 1432261493 total:  50  correct:  48  accuracy: 0.96\n",
      "seed: 1432261494 total:  50  correct:  46  accuracy: 0.92\n",
      "seed: 1432261495 total:  50  correct:  47  accuracy: 0.94\n",
      "seed: 1432261496 total:  50  correct:  46  accuracy: 0.92\n",
      "seed: 1432261497 total:  50  correct:  49  accuracy: 0.98\n",
      "seed: 1432261498 total:  50  correct:  48  accuracy: 0.96\n",
      "seed: 1432261499 total:  50  correct:  47  accuracy: 0.94\n",
      "seed: 1432261500 total:  50  correct:  47  accuracy: 0.94\n",
      "seed: 1432261501 total:  50  correct:  49  accuracy: 0.98\n",
      "seed: 1432261502 total:  50  correct:  46  accuracy: 0.92\n",
      "seed: 1432261503 total:  50  correct:  47  accuracy: 0.94\n",
      "seed: 1432261504 total:  50  correct:  46  accuracy: 0.92\n",
      "seed: 1432261505 total:  50  correct:  50  accuracy: 1.00\n",
      "seed: 1432261506 total:  50  correct:  48  accuracy: 0.96\n",
      "seed: 1432261507 total:  50  correct:  47  accuracy: 0.94\n",
      "seed: 1432261508 total:  50  correct:  47  accuracy: 0.94\n",
      "seed: 1432261509 total:  50  correct:  47  accuracy: 0.94\n",
      "seed: 1432261510 total:  50  correct:  48  accuracy: 0.96\n",
      "seed: 1432261511 total:  50  correct:  48  accuracy: 0.96\n",
      "seed: 1432261512 total:  50  correct:  47  accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "X, Y = iris.data, iris.target\n",
    "import time\n",
    "Now = time.time()\n",
    "print long (Now.real * 100)\n",
    "\n",
    "# Now run the same codeShuffle the data, but make sure that the features and accompanying labels stay in sync.\n",
    "for i in range (0, 50):\n",
    "    myseed = long(Now.real)+i\n",
    "    np.random.seed(myseed)  #  To ensure repeatability of results\n",
    "\n",
    "    shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "    X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "    # Split into train and test.\n",
    "    train_data, train_labels = X[:100], Y[:100]\n",
    "    test_data, test_labels = X[100:], Y[100:]\n",
    "\n",
    "    clf.fit(train_data, train_labels)\n",
    "    preds = clf.predict(test_data)\n",
    "\n",
    "    correct, total = 0, 0\n",
    "    for pred, label in zip(preds, test_labels):\n",
    "        if pred == label: correct += 1\n",
    "        total += 1\n",
    "    print 'seed: %ld total: %3d  correct: %3d  accuracy: %3.2f' %(myseed, total, correct, 1.0*correct/total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy varies with the random seed.  It is normal and expected.  It is important to be aware of this phenomenon: shuffling does matter, and it does affect the classification accuracy.  \n",
    "\n",
    "When you report findings with any ML methodology, or compare your results with someone else's, it is very important to keep it in mind and account for it.\n",
    "\n",
    "As an optional homework, plot the histogram of accuracy after 100 iterations of the Nearest_Neighbors algorithm in this worksheet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
