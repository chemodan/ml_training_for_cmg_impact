{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Classification with Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interest in neural nets, and in particular those with more than than one hidden layer, has been surging in recent years.  In this notebook we will be revisiting the problem of digit classification on the MNIST data.  We will be introducing a new Python library, Theano, for working with neural nets.  Theano is a popular choice as the same code can be run on either CPUs or GPUs.  GPUs greatly speed up the training and prediction, and easily available (Amazon even offers GPU machines on EC2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part 1, we will review the basics of neural nets, and introduce Theano.  In part 2, we will investigate more advanced topics in neural nets, including  deep learning.  I'd encourage you to read this paper as well as a supplementary explanation of Theano (http://www.iro.umontreal.ca/~lisa/pointeurs/theano_scipy2010.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING:theano.configdefaults:g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "===============================\n",
      "'g++' is not recognized as an internal or external command,\r\n",
      "operable program or batch file.\r\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00001\t#include <Python.h>\n",
      "00002\t#include \"structmember.h\"\n",
      "00003\t#include <sys/time.h>\n",
      "00004\t\n",
      "00005\t// Old Python compatibility from here:\n",
      "00006\t// http://www.python.org/dev/peps/pep-0353/\n",
      "00007\t#if PY_VERSION_HEX < 0x02050000 && !defined(PY_SSIZE_T_MIN)\n",
      "00008\ttypedef int Py_ssize_t;\n",
      "00009\t#define PY_SSIZE_T_MAX INT_MAX\n",
      "00010\t#define PY_SSIZE_T_MIN INT_MIN\n",
      "00011\t// This one was taken from:\n",
      "00012\t// http://svn.python.org/projects/python/trunk/Modules/_ctypes/ctypes.h\n",
      "00013\t#define PyNumber_AsSsize_t(ob, exc) PyInt_AsLong(ob)\n",
      "00014\t#endif\n",
      "00015\t\n",
      "00016\t#if PY_VERSION_HEX >= 0x03000000\n",
      "00017\t#include \"numpy/npy_3kcompat.h\"\n",
      "00018\t#define PyCObject_AsVoidPtr  NpyCapsule_AsVoidPtr\n",
      "00019\t#define PyCObject_GetDesc  NpyCapsule_GetDesc\n",
      "00020\t#define PyCObject_Check NpyCapsule_Check\n",
      "00021\t#endif\n",
      "00022\t\n",
      "00023\t#ifndef Py_TYPE\n",
      "00024\t#define Py_TYPE(obj) obj->ob_type\n",
      "00025\t#endif\n",
      "00026\t\n",
      "00027\t/**\n",
      "00028\t\n",
      "00029\tTODO: \n",
      "00030\t- Check max supported depth of recursion\n",
      "00031\t- CLazyLinker should add context information to errors caught during evaluation. Say what node we were on, add the traceback attached to the node.\n",
      "00032\t- Clear containers of fully-useed intermediate results if allow_gc is 1\n",
      "00033\t- Add timers for profiling\n",
      "00034\t- Add support for profiling space used.\n",
      "00035\t\n",
      "00036\t\n",
      "00037\t  */\n",
      "00038\tstatic double pytime(const struct timeval * tv)\n",
      "00039\t{\n",
      "00040\t  struct timeval t;\n",
      "00041\t  if (!tv)\n",
      "00042\t    {\n",
      "00043\t      tv = &t;\n",
      "00044\t      gettimeofday(&t, NULL);\n",
      "00045\t    }\n",
      "00046\t  return (double) tv->tv_sec + (double) tv->tv_usec / 1000000.0;\n",
      "00047\t}\n",
      "00048\t\n",
      "00049\t/**\n",
      "00050\t  Helper routine to convert a PyList of integers to a c array of integers.\n",
      "00051\t  */\n",
      "00052\tstatic int unpack_list_of_ssize_t(PyObject * pylist, Py_ssize_t **dst, Py_ssize_t *len,\n",
      "00053\t                                  const char* kwname)\n",
      "00054\t{\n",
      "00055\t  Py_ssize_t buflen, *buf;\n",
      "00056\t  if (!PyList_Check(pylist))\n",
      "00057\t    {\n",
      "00058\t      PyErr_Format(PyExc_TypeError, \"%s must be list\", kwname);\n",
      "00059\t      return -1;\n",
      "00060\t    }\n",
      "00061\t  assert (NULL == *dst);\n",
      "00062\t  *len = buflen = PyList_Size(pylist);\n",
      "00063\t  *dst = buf = (Py_ssize_t*)calloc(buflen, sizeof(Py_ssize_t));\n",
      "00064\t  assert(buf);\n",
      "00065\t  for (int ii = 0; ii < buflen; ++ii)\n",
      "00066\t    {\n",
      "00067\t      PyObject * el_i = PyList_GetItem(pylist, ii);\n",
      "00068\t      Py_ssize_t n_i = PyNumber_AsSsize_t(el_i, PyExc_IndexError);\n",
      "00069\t      if (PyErr_Occurred())\n",
      "00070\t        {\n",
      "00071\t          free(buf);\n",
      "00072\t          *dst = NULL;\n",
      "00073\t          return -1;\n",
      "00074\t        }\n",
      "00075\t      buf[ii] = n_i;\n",
      "00076\t    }\n",
      "00077\t  return 0;\n",
      "00078\t}\n",
      "00079\t\n",
      "00080\t/**\n",
      "00081\t\n",
      "00082\t  CLazyLinker\n",
      "00083\t\n",
      "00084\t\n",
      "00085\t  */\n",
      "00086\ttypedef struct {\n",
      "00087\t    PyObject_HEAD\n",
      "00088\t    /* Type-specific fields go here. */\n",
      "00089\t    PyObject * nodes; // the python list of nodes\n",
      "00090\t    PyObject * thunks; // python list of thunks\n",
      "00091\t    PyObject * pre_call_clear; //list of cells to clear on call.\n",
      "00092\t    int allow_gc;\n",
      "00093\t    Py_ssize_t n_applies;\n",
      "00094\t    int n_vars;    // number of variables in the graph\n",
      "00095\t    int * var_computed; // 1 or 0 for every variable\n",
      "00096\t    PyObject ** var_computed_cells;\n",
      "00097\t    PyObject ** var_value_cells;\n",
      "00098\t    Py_ssize_t **dependencies; // list of vars dependencies for GC\n",
      "00099\t    Py_ssize_t *n_dependencies;\n",
      "00100\t\n",
      "00101\t    Py_ssize_t n_output_vars;\n",
      "00102\t    Py_ssize_t * output_vars; // variables that *must* be evaluated by call\n",
      "00103\t\n",
      "00104\t    int * is_lazy; // 1 or 0 for every thunk\n",
      "00105\t\n",
      "00106\t    Py_ssize_t * var_owner; // nodes[[var_owner[var_idx]]] is var[var_idx]->owner\n",
      "00107\t    int * var_has_owner; //  1 or 0\n",
      "00108\t\n",
      "00109\t    Py_ssize_t * node_n_inputs;\n",
      "00110\t    Py_ssize_t * node_n_outputs;\n",
      "00111\t    Py_ssize_t ** node_inputs;\n",
      "00112\t    Py_ssize_t ** node_outputs;\n",
      "00113\t    Py_ssize_t * node_inputs_outputs_base; // node_inputs and node_outputs point into this\n",
      "00114\t    Py_ssize_t * node_n_prereqs;\n",
      "00115\t    Py_ssize_t ** node_prereqs;\n",
      "00116\t\n",
      "00117\t    Py_ssize_t * update_storage; // input cells to update with the last outputs in output_vars\n",
      "00118\t    Py_ssize_t n_updates;\n",
      "00119\t\n",
      "00120\t    void ** thunk_cptr_fn;\n",
      "00121\t    void ** thunk_cptr_data;\n",
      "00122\t    PyObject * call_times;\n",
      "00123\t    PyObject * call_counts;\n",
      "00124\t    int do_timing;\n",
      "00125\t    int need_update_inputs;\n",
      "00126\t    int position_of_error; // -1 for no error, otw the index into `thunks` that failed.\n",
      "00127\t} CLazyLinker;\n",
      "00128\t\n",
      "00129\t\n",
      "00130\tstatic void\n",
      "00131\tCLazyLinker_dealloc(PyObject* _self)\n",
      "00132\t{\n",
      "00133\t  CLazyLinker* self = (CLazyLinker *) _self;\n",
      "00134\t  free(self->thunk_cptr_fn);\n",
      "00135\t  free(self->thunk_cptr_data);\n",
      "00136\t\n",
      "00137\t  free(self->is_lazy);\n",
      "00138\t\n",
      "00139\t  free(self->update_storage);\n",
      "00140\t\n",
      "00141\t  if (self->node_n_prereqs)\n",
      "00142\t    {\n",
      "00143\t      for (int i = 0; i < self->n_applies; ++i)\n",
      "00144\t        {\n",
      "00145\t          free(self->node_prereqs[i]);\n",
      "00146\t        }\n",
      "00147\t    }\n",
      "00148\t  free(self->node_n_prereqs);\n",
      "00149\t  free(self->node_prereqs);\n",
      "00150\t  free(self->node_inputs_outputs_base);\n",
      "00151\t  free(self->node_n_inputs);\n",
      "00152\t  free(self->node_n_outputs);\n",
      "00153\t  free(self->node_inputs);\n",
      "00154\t  free(self->node_outputs);\n",
      "00155\t\n",
      "00156\t  if (self->dependencies)\n",
      "00157\t    {\n",
      "00158\t      for (int i = 0; i < self->n_vars; ++i)\n",
      "00159\t        {\n",
      "00160\t          free(self->dependencies[i]);\n",
      "00161\t        }\n",
      "00162\t      free(self->dependencies);\n",
      "00163\t      free(self->n_dependencies);\n",
      "00164\t    }\n",
      "00165\t\n",
      "00166\t  free(self->var_owner);\n",
      "00167\t  free(self->var_has_owner);\n",
      "00168\t  free(self->var_computed);\n",
      "00169\t  if (self->var_computed_cells)\n",
      "00170\t    {\n",
      "00171\t      for (int i = 0; i < self->n_vars; ++i)\n",
      "00172\t        {\n",
      "00173\t          Py_DECREF(self->var_computed_cells[i]);\n",
      "00174\t          Py_DECREF(self->var_value_cells[i]);\n",
      "00175\t        }\n",
      "00176\t    }\n",
      "00177\t  free(self->var_computed_cells);\n",
      "00178\t  free(self->var_value_cells);\n",
      "00179\t  free(self->output_vars);\n",
      "00180\t\n",
      "00181\t  Py_XDECREF(self->nodes);\n",
      "00182\t  Py_XDECREF(self->thunks);\n",
      "00183\t  Py_XDECREF(self->call_times);\n",
      "00184\t  Py_XDECREF(self->call_counts);\n",
      "00185\t  Py_XDECREF(self->pre_call_clear);\n",
      "00186\t  Py_TYPE(self)->tp_free((PyObject*)self);\n",
      "00187\t}\n",
      "00188\tstatic PyObject *\n",
      "00189\tCLazyLinker_new(PyTypeObject *type, PyObject *args, PyObject *kwds)\n",
      "00190\t{\n",
      "00191\t    CLazyLinker *self;\n",
      "00192\t\n",
      "00193\t    self = (CLazyLinker *)type->tp_alloc(type, 0);\n",
      "00194\t    if (self != NULL) {\n",
      "00195\t      self->nodes = NULL;\n",
      "00196\t      self->thunks = NULL;\n",
      "00197\t      self->pre_call_clear = NULL;\n",
      "00198\t\n",
      "00199\t      self->allow_gc = 1;\n",
      "00200\t      self->n_applies = 0;\n",
      "00201\t      self->n_vars = 0;\n",
      "00202\t      self->var_computed = NULL;\n",
      "00203\t      self->var_computed_cells = NULL;\n",
      "00204\t      self->var_value_cells = NULL;\n",
      "00205\t      self->dependencies = NULL;\n",
      "00206\t      self->n_dependencies = NULL;\n",
      "00207\t\n",
      "00208\t      self->n_output_vars = 0;\n",
      "00209\t      self->output_vars = NULL;\n",
      "00210\t\n",
      "00211\t      self->is_lazy = NULL;\n",
      "00212\t\n",
      "00213\t      self->var_owner = NULL;\n",
      "00214\t      self->var_has_owner = NULL;\n",
      "00215\t\n",
      "00216\t      self->node_n_inputs = NULL;\n",
      "00217\t      self->node_n_outputs = NULL;\n",
      "00218\t      self->node_inputs = NULL;\n",
      "00219\t      self->node_outputs = NULL;\n",
      "00220\t      self->node_inputs_outputs_base = NULL;\n",
      "00221\t      self->node_prereqs = NULL;\n",
      "00222\t      self->node_n_prereqs = NULL;\n",
      "00223\t\n",
      "00224\t      self->update_storage = NULL;\n",
      "00225\t      self->n_updates = 0;\n",
      "00226\t\n",
      "00227\t      self->thunk_cptr_data = NULL;\n",
      "00228\t      self->thunk_cptr_fn = NULL;\n",
      "00229\t      self->call_times = NULL;\n",
      "00230\t      self->call_counts = NULL;\n",
      "00231\t      self->do_timing = 0;\n",
      "00232\t\n",
      "00233\t      self->need_update_inputs = 0;\n",
      "00234\t      self->position_of_error = -1;\n",
      "00235\t    }\n",
      "00236\t    return (PyObject *)self;\n",
      "00237\t}\n",
      "00238\t\n",
      "00239\tstatic int\n",
      "00240\tCLazyLinker_init(CLazyLinker *self, PyObject *args, PyObject *kwds)\n",
      "00241\t{\n",
      "00242\t    static char *kwlist[] = {\n",
      "00243\t      (char*)\"nodes\",\n",
      "00244\t      (char*)\"thunks\",\n",
      "00245\t      (char*)\"pre_call_clear\",\n",
      "00246\t      (char*)\"allow_gc\",\n",
      "00247\t      (char*)\"call_counts\",\n",
      "00248\t      (char*)\"call_times\",\n",
      "00249\t      (char*)\"compute_map_list\",\n",
      "00250\t      (char*)\"storage_map_list\",\n",
      "00251\t      (char*)\"base_input_output_list\",\n",
      "00252\t      (char*)\"node_n_inputs\",\n",
      "00253\t      (char*)\"node_n_outputs\",\n",
      "00254\t      (char*)\"node_input_offset\",\n",
      "00255\t      (char*)\"node_output_offset\",\n",
      "00256\t      (char*)\"var_owner\",\n",
      "00257\t      (char*)\"is_lazy_list\",\n",
      "00258\t      (char*)\"output_vars\",\n",
      "00259\t      (char*)\"node_prereqs\",\n",
      "00260\t      (char*)\"node_output_size\",\n",
      "00261\t      (char*)\"update_storage\",\n",
      "00262\t      (char*)\"dependencies\",\n",
      "00263\t      NULL};\n",
      "00264\t\n",
      "00265\t    PyObject *compute_map_list=NULL,\n",
      "00266\t             *storage_map_list=NULL,\n",
      "00267\t             *base_input_output_list=NULL,\n",
      "00268\t             *node_n_inputs=NULL,\n",
      "00269\t             *node_n_outputs=NULL,\n",
      "00270\t             *node_input_offset=NULL,\n",
      "00271\t             *node_output_offset=NULL,\n",
      "00272\t             *var_owner=NULL,\n",
      "00273\t             *is_lazy=NULL,\n",
      "00274\t             *output_vars=NULL,\n",
      "00275\t             *node_prereqs=NULL,\n",
      "00276\t             *node_output_size=NULL,\n",
      "00277\t             *update_storage=NULL,\n",
      "00278\t             *dependencies=NULL;\n",
      "00279\t\n",
      "00280\t    assert(!self->nodes);\n",
      "00281\t    if (! PyArg_ParseTupleAndKeywords(args, kwds, \"OOOiOOOOOOOOOOOOOOOO\", kwlist,\n",
      "00282\t                                      &self->nodes,\n",
      "00283\t                                      &self->thunks,\n",
      "00284\t                                      &self->pre_call_clear,\n",
      "00285\t                                      &self->allow_gc,\n",
      "00286\t                                      &self->call_counts,\n",
      "00287\t                                      &self->call_times,\n",
      "00288\t                                      &compute_map_list,\n",
      "00289\t                                      &storage_map_list,\n",
      "00290\t                                      &base_input_output_list,\n",
      "00291\t                                      &node_n_inputs,\n",
      "00292\t                                      &node_n_outputs,\n",
      "00293\t                                      &node_input_offset,\n",
      "00294\t                                      &node_output_offset,\n",
      "00295\t                                      &var_owner,\n",
      "00296\t                                      &is_lazy,\n",
      "00297\t                                      &output_vars,\n",
      "00298\t                                      &node_prereqs,\n",
      "00299\t                                      &node_output_size,\n",
      "00300\t                                      &update_storage,\n",
      "00301\t                                      &dependencies\n",
      "00302\t                                      ))\n",
      "00303\t        return -1;\n",
      "00304\t    Py_INCREF(self->nodes);\n",
      "00305\t    Py_INCREF(self->thunks);\n",
      "00306\t    Py_INCREF(self->pre_call_clear);\n",
      "00307\t    Py_INCREF(self->call_counts);\n",
      "00308\t    Py_INCREF(self->call_times);\n",
      "00309\t\n",
      "00310\t    Py_ssize_t n_applies = PyList_Size(self->nodes);\n",
      "00311\t\n",
      "00312\t    self->n_applies = n_applies;\n",
      "00313\t    self->n_vars = PyList_Size(var_owner);\n",
      "00314\t\n",
      "00315\t    if (PyList_Size(self->thunks) != n_applies) return -1;\n",
      "00316\t    if (PyList_Size(self->call_counts) != n_applies) return -1;\n",
      "00317\t    if (PyList_Size(self->call_times) != n_applies) return -1;\n",
      "00318\t\n",
      "00319\t    // allocated and initialize thunk_cptr_data and thunk_cptr_fn\n",
      "00320\t    if (n_applies)\n",
      "00321\t      {\n",
      "00322\t        self->thunk_cptr_data = (void**)calloc(n_applies, sizeof(void*));\n",
      "00323\t        self->thunk_cptr_fn = (void**)calloc(n_applies, sizeof(void*));\n",
      "00324\t        self->is_lazy = (int*)calloc(n_applies, sizeof(int));\n",
      "00325\t        self->node_prereqs = (Py_ssize_t**)calloc(n_applies, sizeof(Py_ssize_t*));\n",
      "00326\t        self->node_n_prereqs = (Py_ssize_t*)calloc(n_applies, sizeof(Py_ssize_t));\n",
      "00327\t        assert(self->node_prereqs);\n",
      "00328\t        assert(self->node_n_prereqs);\n",
      "00329\t        assert(self->is_lazy);\n",
      "00330\t        assert(self->thunk_cptr_fn);\n",
      "00331\t        assert(self->thunk_cptr_data);\n",
      "00332\t\n",
      "00333\t        for (int i = 0; i < n_applies; ++i)\n",
      "00334\t          {\n",
      "00335\t            PyObject * thunk = PyList_GetItem(self->thunks, i);\n",
      "00336\t            //thunk is borrowed\n",
      "00337\t            if (PyObject_HasAttrString(thunk, \"cthunk\"))\n",
      "00338\t              {\n",
      "00339\t                PyObject * cthunk = PyObject_GetAttrString(thunk, \"cthunk\");\n",
      "00340\t                //new reference\n",
      "00341\t                assert (cthunk && PyCObject_Check(cthunk));\n",
      "00342\t                self->thunk_cptr_fn[i] = PyCObject_AsVoidPtr(cthunk);\n",
      "00343\t                self->thunk_cptr_data[i] = PyCObject_GetDesc(cthunk);\n",
      "00344\t                Py_DECREF(cthunk);\n",
      "00345\t                // cthunk is kept alive by membership in self->thunks\n",
      "00346\t              }\n",
      "00347\t\n",
      "00348\t            PyObject * el_i = PyList_GetItem(is_lazy, i);\n",
      "00349\t            self->is_lazy[i] = PyNumber_AsSsize_t(el_i, NULL);\n",
      "00350\t\n",
      "00351\t            /* now get the prereqs */\n",
      "00352\t            el_i = PyList_GetItem(node_prereqs, i);\n",
      "00353\t            assert (PyList_Check(el_i));\n",
      "00354\t            self->node_n_prereqs[i] = PyList_Size(el_i);\n",
      "00355\t            if (self->node_n_prereqs[i])\n",
      "00356\t              {\n",
      "00357\t                self->node_prereqs[i] = (Py_ssize_t*)malloc(\n",
      "00358\t                              PyList_Size(el_i)*sizeof(Py_ssize_t));\n",
      "00359\t                for (int j = 0; j < PyList_Size(el_i); ++j)\n",
      "00360\t                  {\n",
      "00361\t                    PyObject * el_ij = PyList_GetItem(el_i, j);\n",
      "00362\t                    Py_ssize_t N = PyNumber_AsSsize_t(el_ij, PyExc_IndexError);\n",
      "00363\t                    if (PyErr_Occurred())\n",
      "00364\t                      return -1;\n",
      "00365\t                    // N < n. variables\n",
      "00366\t                    assert(N < PyList_Size(var_owner));\n",
      "00367\t                    self->node_prereqs[i][j] = N;\n",
      "00368\t                  }\n",
      "00369\t              }\n",
      "00370\t          }\n",
      "00371\t      }\n",
      "00372\t    if (PyList_Check(base_input_output_list))\n",
      "00373\t      {\n",
      "00374\t        Py_ssize_t n_inputs_outputs_base = PyList_Size(base_input_output_list);\n",
      "00375\t        self->node_inputs_outputs_base = (Py_ssize_t*)calloc(n_inputs_outputs_base,sizeof(Py_ssize_t));\n",
      "00376\t        assert(self->node_inputs_outputs_base);\n",
      "00377\t        for (int i = 0; i < n_inputs_outputs_base; ++i)\n",
      "00378\t          {\n",
      "00379\t            PyObject *el_i = PyList_GetItem(base_input_output_list, i);\n",
      "00380\t            Py_ssize_t idx = PyNumber_AsSsize_t(el_i, PyExc_IndexError);\n",
      "00381\t            if (PyErr_Occurred()) return -1;\n",
      "00382\t            self->node_inputs_outputs_base[i] = idx;\n",
      "00383\t          }\n",
      "00384\t        self->node_n_inputs = (Py_ssize_t*)calloc(n_applies,sizeof(Py_ssize_t));\n",
      "00385\t        assert(self->node_n_inputs);\n",
      "00386\t        self->node_n_outputs = (Py_ssize_t*)calloc(n_applies,sizeof(Py_ssize_t));\n",
      "00387\t        assert(self->node_n_outputs);\n",
      "00388\t        self->node_inputs = (Py_ssize_t**)calloc(n_applies,sizeof(Py_ssize_t*));\n",
      "00389\t        assert(self->node_inputs);\n",
      "00390\t        self->node_outputs = (Py_ssize_t**)calloc(n_applies,sizeof(Py_ssize_t*));\n",
      "00391\t        assert(self->node_outputs);\n",
      "00392\t        for (int i = 0; i < n_applies; ++i)\n",
      "00393\t          {\n",
      "00394\t            Py_ssize_t N;\n",
      "00395\t            N = PyNumber_AsSsize_t(PyList_GetItem(node_n_inputs, i),PyExc_IndexError);\n",
      "00396\t            if (PyErr_Occurred()) return -1;\n",
      "00397\t            assert (N <= n_inputs_outputs_base);\n",
      "00398\t            self->node_n_inputs[i] = N;\n",
      "00399\t            N = PyNumber_AsSsize_t(PyList_GetItem(node_n_outputs, i),PyExc_IndexError);\n",
      "00400\t            if (PyErr_Occurred()) return -1;\n",
      "00401\t            assert (N <= n_inputs_outputs_base);\n",
      "00402\t            self->node_n_outputs[i] = N;\n",
      "00403\t            N = PyNumber_AsSsize_t(PyList_GetItem(node_input_offset, i),PyExc_IndexError);\n",
      "00404\t            if (PyErr_Occurred()) return -1;\n",
      "00405\t            assert (N <= n_inputs_outputs_base);\n",
      "00406\t            self->node_inputs[i] = &self->node_inputs_outputs_base[N];\n",
      "00407\t            N = PyNumber_AsSsize_t(PyList_GetItem(node_output_offset, i),PyExc_IndexError);\n",
      "00408\t            if (PyErr_Occurred()) return -1;\n",
      "00409\t            assert (N <= n_inputs_outputs_base);\n",
      "00410\t            self->node_outputs[i] = &self->node_inputs_outputs_base[N];\n",
      "00411\t          }\n",
      "00412\t      }\n",
      "00413\t    else\n",
      "00414\t      {\n",
      "00415\t        PyErr_SetString(PyExc_TypeError, \"base_input_output_list must be list\");\n",
      "00416\t        return -1;\n",
      "00417\t      }\n",
      "00418\t\n",
      "00419\t    // allocation for var_owner\n",
      "00420\t    if (PyList_Check(var_owner))\n",
      "00421\t      {\n",
      "00422\t        self->var_owner = (Py_ssize_t*)calloc(self->n_vars,sizeof(Py_ssize_t));\n",
      "00423\t        self->var_has_owner = (int*)calloc(self->n_vars,sizeof(int));\n",
      "00424\t        self->var_computed = (int*)calloc(self->n_vars,sizeof(int));\n",
      "00425\t        self->var_computed_cells = (PyObject**)calloc(self->n_vars,sizeof(PyObject*));\n",
      "00426\t        self->var_value_cells = (PyObject**)calloc(self->n_vars,sizeof(PyObject*));\n",
      "00427\t        for (int i = 0; i < self->n_vars; ++i)\n",
      "00428\t          {\n",
      "00429\t            PyObject * el_i = PyList_GetItem(var_owner, i);\n",
      "00430\t            if (el_i == Py_None)\n",
      "00431\t              {\n",
      "00432\t                self->var_has_owner[i] = 0;\n",
      "00433\t              }\n",
      "00434\t            else\n",
      "00435\t              {\n",
      "00436\t                Py_ssize_t N = PyNumber_AsSsize_t(el_i, PyExc_IndexError);\n",
      "00437\t                if (PyErr_Occurred()) return -1;\n",
      "00438\t                assert (N <= n_applies);\n",
      "00439\t                self->var_owner[i] = N;\n",
      "00440\t                self->var_has_owner[i] = 1;\n",
      "00441\t              }\n",
      "00442\t            self->var_computed_cells[i] = PyList_GetItem(compute_map_list, i);\n",
      "00443\t            Py_INCREF(self->var_computed_cells[i]);\n",
      "00444\t            self->var_value_cells[i] = PyList_GetItem(storage_map_list, i);\n",
      "00445\t            Py_INCREF(self->var_value_cells[i]);\n",
      "00446\t          }\n",
      "00447\t      }\n",
      "00448\t    else\n",
      "00449\t      {\n",
      "00450\t        PyErr_SetString(PyExc_TypeError, \"var_owner must be list\");\n",
      "00451\t        return -1;\n",
      "00452\t      }\n",
      "00453\t\n",
      "00454\t    if (dependencies != Py_None)\n",
      "00455\t      {\n",
      "00456\t        self->dependencies = (Py_ssize_t**)calloc(self->n_vars, sizeof(Py_ssize_t *));\n",
      "00457\t        self->n_dependencies = (Py_ssize_t*)calloc(self->n_vars, sizeof(Py_ssize_t));\n",
      "00458\t        assert(self->dependencies);\n",
      "00459\t        assert(self->n_dependencies);\n",
      "00460\t\n",
      "00461\t        for (int i = 0; i < self->n_vars; ++i)\n",
      "00462\t          {\n",
      "00463\t            PyObject *tmp = PyList_GetItem(dependencies, i);\n",
      "00464\t            // refcounting - tmp is borrowed\n",
      "00465\t            if (unpack_list_of_ssize_t(tmp, &self->dependencies[i], &self->n_dependencies[i],\n",
      "00466\t                                       \"dependencies\"))\n",
      "00467\t              return -1;\n",
      "00468\t          }\n",
      "00469\t      }\n",
      "00470\t\n",
      "00471\t    if (unpack_list_of_ssize_t(output_vars, &self->output_vars, &self->n_output_vars,\n",
      "00472\t                               \"output_vars\"))\n",
      "00473\t      return -1;\n",
      "00474\t    for (int i = 0; i < self->n_output_vars; ++i)\n",
      "00475\t      {\n",
      "00476\t        assert(self->output_vars[i] < self->n_vars);\n",
      "00477\t      }\n",
      "00478\t    if (unpack_list_of_ssize_t(update_storage, &self->update_storage, &self->n_updates,\n",
      "00479\t                               \"updates_storage\"))\n",
      "00480\t      return -1;\n",
      "00481\t    return 0;\n",
      "00482\t}\n",
      "00483\tstatic void set_position_of_error(CLazyLinker * self, int owner_idx)\n",
      "00484\t{\n",
      "00485\t  if (self->position_of_error == -1)\n",
      "00486\t    {\n",
      "00487\t      self->position_of_error = owner_idx;\n",
      "00488\t    }\n",
      "00489\t}\n",
      "00490\tstatic PyObject * pycall(CLazyLinker * self, Py_ssize_t node_idx, int verbose)\n",
      "00491\t{\n",
      "00492\t  // call thunk to see which inputs it wants\n",
      "00493\t  PyObject * thunk = PyList_GetItem(self->thunks, node_idx);\n",
      "00494\t  // refcounting - thunk is borrowed\n",
      "00495\t  PyObject * rval = NULL;\n",
      "00496\t  if (self->do_timing)\n",
      "00497\t    {\n",
      "00498\t      double t0 = pytime(NULL);\n",
      "00499\t      if (verbose) fprintf(stderr, \"calling via Python (node %i)\\n\", (int)node_idx);\n",
      "00500\t      rval = PyObject_CallObject(thunk, NULL);\n",
      "00501\t      if (rval)\n",
      "00502\t        {\n",
      "00503\t          double t1 = pytime(NULL);\n",
      "00504\t          double ti = PyFloat_AsDouble(\n",
      "00505\t                         PyList_GetItem(self->call_times, node_idx));\n",
      "00506\t          PyList_SetItem(self->call_times, node_idx,\n",
      "00507\t                         PyFloat_FromDouble(t1 - t0 + ti));\n",
      "00508\t          PyObject * count = PyList_GetItem(self->call_counts, node_idx);\n",
      "00509\t          long icount = PyInt_AsLong(count);\n",
      "00510\t          PyList_SetItem(self->call_counts, node_idx,\n",
      "00511\t                         PyInt_FromLong(icount + 1));\n",
      "00512\t      }\n",
      "00513\t    }\n",
      "00514\t  else\n",
      "00515\t    {\n",
      "00516\t      if (verbose)\n",
      "00517\t        {\n",
      "00518\t          fprintf(stderr, \"calling via Python (node %i)\\n\", (int)node_idx);\n",
      "00519\t        }\n",
      "00520\t      rval = PyObject_CallObject(thunk, NULL);\n",
      "00521\t    }\n",
      "00522\t  return rval;\n",
      "00523\t}\n",
      "00524\tstatic int c_call(CLazyLinker * self, Py_ssize_t node_idx, int verbose)\n",
      "00525\t{\n",
      "00526\t  void * ptr_addr = self->thunk_cptr_fn[node_idx];\n",
      "00527\t  int (*fn)(void*) = (int (*)(void*))(ptr_addr);\n",
      "00528\t  if (verbose) fprintf(stderr, \"calling non-lazy shortcut (node %i)\\n\", (int)node_idx);\n",
      "00529\t  int err = 0;\n",
      "00530\t  if (self->do_timing)\n",
      "00531\t    {\n",
      "00532\t      double t0 = pytime(NULL);\n",
      "00533\t      err = fn(self->thunk_cptr_data[node_idx]);\n",
      "00534\t      double t1 = pytime(NULL);\n",
      "00535\t      double ti = PyFloat_AsDouble(PyList_GetItem(self->call_times, node_idx));\n",
      "00536\t      PyList_SetItem(self->call_times, node_idx, PyFloat_FromDouble(t1 - t0 + ti));\n",
      "00537\t      PyObject * count = PyList_GetItem(self->call_counts, node_idx);\n",
      "00538\t      long icount = PyInt_AsLong(count);\n",
      "00539\t      PyList_SetItem(self->call_counts, node_idx, PyInt_FromLong(icount+1));\n",
      "00540\t    }\n",
      "00541\t  else\n",
      "00542\t    {\n",
      "00543\t      err = fn(self->thunk_cptr_data[node_idx]);\n",
      "00544\t    }\n",
      "00545\t\n",
      "00546\t  if (err)\n",
      "00547\t    {\n",
      "00548\t      // cast the argument to a PyList (as described near line 226 of cc.py)\n",
      "00549\t      PyObject * __ERROR = ((PyObject**)self->thunk_cptr_data[node_idx])[0];\n",
      "00550\t      assert (PyList_Check(__ERROR));\n",
      "00551\t      assert (PyList_Size(__ERROR) == 3);\n",
      "00552\t      PyObject * err_type = PyList_GetItem(__ERROR, 0); //stolen ref\n",
      "00553\t      PyObject * err_msg = PyList_GetItem(__ERROR, 1); //stolen ref\n",
      "00554\t      PyObject * err_trace = PyList_GetItem(__ERROR, 2); //stolen ref\n",
      "00555\t      PyList_SET_ITEM(__ERROR, 0, Py_None); Py_INCREF(Py_None); //clobbers old ref\n",
      "00556\t      PyList_SET_ITEM(__ERROR, 1, Py_None); Py_INCREF(Py_None); //clobbers old ref\n",
      "00557\t      PyList_SET_ITEM(__ERROR, 2, Py_None); Py_INCREF(Py_None); //clobbers old ref\n",
      "00558\t\n",
      "00559\t      assert(!PyErr_Occurred()); // because CLinker hid the exception in __ERROR aka data\n",
      "00560\t      PyErr_Restore(err_type, err_msg, err_trace); //steals refs to args\n",
      "00561\t    }\n",
      "00562\t  if (err) set_position_of_error(self, node_idx);\n",
      "00563\t  return err;\n",
      "00564\t}\n",
      "00565\tstatic\n",
      "00566\tint lazy_rec_eval(CLazyLinker * self, Py_ssize_t var_idx, PyObject*one, PyObject*zero)\n",
      "00567\t{\n",
      "00568\t  PyObject *rval = NULL;\n",
      "00569\t  int verbose = 0;\n",
      "00570\t  int err = 0;\n",
      "00571\t\n",
      "00572\t  if (verbose) fprintf(stderr, \"lazy_rec computing %i\\n\", (int)var_idx);\n",
      "00573\t\n",
      "00574\t  if (self->var_computed[var_idx] || !self->var_has_owner[var_idx])\n",
      "00575\t    return 0;\n",
      "00576\t\n",
      "00577\t  Py_ssize_t owner_idx = self->var_owner[var_idx];\n",
      "00578\t\n",
      "00579\t  // STEP 1: compute the pre-requirements of the node\n",
      "00580\t  // Includes input nodes for non-lazy ops.\n",
      "00581\t  for (int i = 0; i < self->node_n_prereqs[owner_idx]; ++i)\n",
      "00582\t    {\n",
      "00583\t      Py_ssize_t prereq_idx = self->node_prereqs[owner_idx][i];\n",
      "00584\t      if (!self->var_computed[prereq_idx])\n",
      "00585\t        {\n",
      "00586\t          err = lazy_rec_eval(self, prereq_idx, one, zero);\n",
      "00587\t          if (err) return err;\n",
      "00588\t        }\n",
      "00589\t      assert (self->var_computed[prereq_idx]);\n",
      "00590\t    }\n",
      "00591\t\n",
      "00592\t  // STEP 2: compute the node itself\n",
      "00593\t  if (self->is_lazy[owner_idx])\n",
      "00594\t    {\n",
      "00595\t      // update the compute_map cells corresponding to the inputs of this thunk\n",
      "00596\t      for (int i = 0; i < self->node_n_inputs[owner_idx]; ++i)\n",
      "00597\t        {\n",
      "00598\t          int in_idx = self->node_inputs[owner_idx][i];\n",
      "00599\t          if (self->var_computed[in_idx])\n",
      "00600\t            {\n",
      "00601\t              Py_INCREF(one);\n",
      "00602\t              err = PyList_SetItem(self->var_computed_cells[in_idx], 0, one);\n",
      "00603\t            }\n",
      "00604\t          else\n",
      "00605\t            {\n",
      "00606\t              Py_INCREF(zero);\n",
      "00607\t              err = PyList_SetItem(self->var_computed_cells[in_idx], 0, zero);\n",
      "00608\t            }\n",
      "00609\t          if (err) goto fail;\n",
      "00610\t        }\n",
      "00611\t\n",
      "00612\t      rval = pycall(self, owner_idx, verbose);\n",
      "00613\t      // refcounting - rval is new ref\n",
      "00614\t      //TODO: to prevent infinite loops\n",
      "00615\t      // - consider check that a thunk does not ask for an input that is already computed\n",
      "00616\t      if (rval == NULL)\n",
      "00617\t        {\n",
      "00618\t          assert (PyErr_Occurred());\n",
      "00619\t          err = 1;\n",
      "00620\t          goto fail;\n",
      "00621\t        }\n",
      "00622\t\n",
      "00623\t      //update the computed-ness of any output cells\n",
      "00624\t      for (int i = 0; i < self->node_n_outputs[owner_idx]; ++i)\n",
      "00625\t        {\n",
      "00626\t          int out_idx = self->node_outputs[owner_idx][i];\n",
      "00627\t          PyObject * el_i = PyList_GetItem(self->var_computed_cells[out_idx], 0);\n",
      "00628\t          Py_ssize_t N = PyNumber_AsSsize_t(el_i, PyExc_IndexError);\n",
      "00629\t          if (PyErr_Occurred())\n",
      "00630\t            {\n",
      "00631\t              err = -1;\n",
      "00632\t              goto pyfail;\n",
      "00633\t            }\n",
      "00634\t          assert (N==0 || N==1);\n",
      "00635\t          self->var_computed[out_idx] = N;\n",
      "00636\t        }\n",
      "00637\t      if (!self->var_computed[var_idx])\n",
      "00638\t        {\n",
      "00639\t          /*\n",
      "00640\t           * If self is not computed after the call, this means that some\n",
      "00641\t           * inputs are needed.  Compute the ones on the returned list\n",
      "00642\t           * and try to compute the current node again (with recursive call).\n",
      "00643\t           * This allows a node to request more nodes more than once before\n",
      "00644\t           * finally yielding a result.\n",
      "00645\t           */\n",
      "00646\t          if (!PyList_Check(rval))\n",
      "00647\t            {\n",
      "00648\t              //TODO: More helpful error to help find *which node* made this\n",
      "00649\t              // bad thunk\n",
      "00650\t              PyErr_SetString(PyExc_TypeError,\n",
      "00651\t                              \"lazy thunk should return a list\");\n",
      "00652\t              err = 1;\n",
      "00653\t              goto pyfail;\n",
      "00654\t            }\n",
      "00655\t\n",
      "00656\t          if (!PyList_Size(rval))\n",
      "00657\t            {\n",
      "00658\t              PyErr_SetString(PyExc_ValueError,\n",
      "00659\t                              \"lazy thunk returned empty list without computing output\");\n",
      "00660\t              err = 1;\n",
      "00661\t              goto pyfail;\n",
      "00662\t            }\n",
      "00663\t\n",
      "00664\t          for (int i = 0; i < PyList_Size(rval); ++i)\n",
      "00665\t            {\n",
      "00666\t              PyObject * el_i = PyList_GetItem(rval, i);\n",
      "00667\t              Py_ssize_t N = PyNumber_AsSsize_t(el_i, PyExc_IndexError);\n",
      "00668\t              if (PyErr_Occurred())\n",
      "00669\t                {\n",
      "00670\t                  err = 1;\n",
      "00671\t                  goto pyfail;\n",
      "00672\t                }\n",
      "00673\t              assert (N <= self->node_n_inputs[owner_idx]);\n",
      "00674\t              Py_ssize_t input_idx = self->node_inputs[owner_idx][N];\n",
      "00675\t              err = lazy_rec_eval(self, input_idx, one, zero);\n",
      "00676\t              if (err) goto pyfail;\n",
      "00677\t            }\n",
      "00678\t\n",
      "00679\t          Py_DECREF(rval);\n",
      "00680\t          /*\n",
      "00681\t           * We intentionally skip all the end-of-function processing\n",
      "00682\t           * (mark outputs, GC) as it will be performed by the call\n",
      "00683\t           * that actually manages to compute the result.\n",
      "00684\t           */\n",
      "00685\t          return lazy_rec_eval(self, var_idx, one, zero);\n",
      "00686\t        }\n",
      "00687\t\n",
      "00688\t      Py_DECREF(rval);\n",
      "00689\t    }\n",
      "00690\t  else //owner is not a lazy op. Ensure all intputs are evaluated.\n",
      "00691\t    {\n",
      "00692\t      // loop over inputs to owner\n",
      "00693\t      // call lazy_rec_eval on each one that is not computed.\n",
      "00694\t      // if there's an error, pass it up the stack\n",
      "00695\t      for (int i = 0; i < self->node_n_inputs[owner_idx]; ++i)\n",
      "00696\t        {\n",
      "00697\t          Py_ssize_t input_idx = self->node_inputs[owner_idx][i];\n",
      "00698\t          if (!self->var_computed[input_idx])\n",
      "00699\t            {\n",
      "00700\t              err = lazy_rec_eval(self, input_idx, one, zero);\n",
      "00701\t              if (err) return err;\n",
      "00702\t            }\n",
      "00703\t          assert (self->var_computed[input_idx]);\n",
      "00704\t        }\n",
      "00705\t\n",
      "00706\t      // call the thunk for this owner.\n",
      "00707\t      if (self->thunk_cptr_fn[owner_idx])\n",
      "00708\t        {\n",
      "00709\t          err = c_call(self, owner_idx, verbose);\n",
      "00710\t          if (err) goto fail;\n",
      "00711\t        }\n",
      "00712\t      else\n",
      "00713\t        {\n",
      "00714\t          rval = pycall(self, owner_idx, verbose);\n",
      "00715\t          //rval is new ref\n",
      "00716\t          if (rval) //pycall returned normally (no exception)\n",
      "00717\t            {\n",
      "00718\t              if (rval == Py_None)\n",
      "00719\t                {\n",
      "00720\t                  Py_DECREF(rval); //ignore a return of None\n",
      "00721\t                }\n",
      "00722\t              else if (PyList_Check(rval))\n",
      "00723\t                {\n",
      "00724\t                  PyErr_SetString(PyExc_TypeError,\n",
      "00725\t                                  \"non-lazy thunk should return None, not list\");\n",
      "00726\t                  err = 1;\n",
      "00727\t                  goto pyfail;\n",
      "00728\t                }\n",
      "00729\t              else // don't know what it returned, but it wasn't right.\n",
      "00730\t                {\n",
      "00731\t                  PyErr_SetObject(PyExc_TypeError, rval);\n",
      "00732\t                  err = 1;\n",
      "00733\t                  // We don't release rval since we put it in the error above\n",
      "00734\t                  goto fail;\n",
      "00735\t                }\n",
      "00736\t            }\n",
      "00737\t          else // pycall returned NULL (internal error)\n",
      "00738\t            {\n",
      "00739\t              err = 1;\n",
      "00740\t              goto fail;\n",
      "00741\t            }\n",
      "00742\t        }\n",
      "00743\t    }\n",
      "00744\t\n",
      "00745\t  // loop over all outputs and mark them as computed\n",
      "00746\t  for (int i = 0; i < self->node_n_outputs[owner_idx]; ++i)\n",
      "00747\t    {\n",
      "00748\t      self->var_computed[self->node_outputs[owner_idx][i]] = 1;\n",
      "00749\t    }\n",
      "00750\t\n",
      "00751\t  // Free vars that are not needed anymore\n",
      "00752\t  if (self->allow_gc)\n",
      "00753\t    {\n",
      "00754\t      for (int i = 0; i < self->node_n_inputs[owner_idx]; ++i)\n",
      "00755\t        {\n",
      "00756\t          int cleanup = 1;\n",
      "00757\t          Py_ssize_t i_idx = self->node_inputs[owner_idx][i];\n",
      "00758\t          if (!self->var_has_owner[i_idx])\n",
      "00759\t            continue;\n",
      "00760\t\n",
      "00761\t          for (int j = 0; j < self->n_output_vars; ++j)\n",
      "00762\t            {\n",
      "00763\t              if (i_idx == self->output_vars[j])\n",
      "00764\t                {\n",
      "00765\t                  cleanup = 0;\n",
      "00766\t                  break;\n",
      "00767\t                }\n",
      "00768\t            }\n",
      "00769\t          if (!cleanup) continue;\n",
      "00770\t\n",
      "00771\t          for (int j = 0; j < self->n_dependencies[i_idx]; ++j)\n",
      "00772\t            {\n",
      "00773\t              if (!self->var_computed[self->dependencies[i_idx][j]])\n",
      "00774\t                {\n",
      "00775\t                  cleanup = 0;\n",
      "00776\t                  break;\n",
      "00777\t                }\n",
      "00778\t            }\n",
      "00779\t          if (!cleanup) continue;\n",
      "00780\t\n",
      "00781\t          Py_INCREF(Py_None);\n",
      "00782\t          err = PyList_SetItem(self->var_value_cells[i_idx], 0, Py_None);\n",
      "00783\t//See the Stack gc implementation for why we change it to 2 and not 0.\n",
      "00784\t          self->var_computed[i_idx] = 2;\n",
      "00785\t          if (err) goto fail;\n",
      "00786\t        }\n",
      "00787\t    }\n",
      "00788\t\n",
      "00789\t  return 0;\n",
      "00790\t pyfail:\n",
      "00791\t  Py_DECREF(rval);\n",
      "00792\t fail:\n",
      "00793\t  set_position_of_error(self, owner_idx);\n",
      "00794\t  return err;\n",
      "00795\t}\n",
      "00796\t\n",
      "00797\tstatic PyObject *\n",
      "00798\tCLazyLinker_call(PyObject *_self, PyObject *args, PyObject *kwds)\n",
      "00799\t{\n",
      "00800\t  CLazyLinker * self = (CLazyLinker*)_self;\n",
      "00801\t  static char *kwlist[] = {\n",
      "00802\t    (char*)\"time_thunks\",\n",
      "00803\t    (char *)\"n_calls\",\n",
      "00804\t    NULL};\n",
      "00805\t  int n_calls=1;\n",
      "00806\t  if (! PyArg_ParseTupleAndKeywords(args, kwds, \"|ii\", kwlist,\n",
      "00807\t                                    &self->do_timing,\n",
      "00808\t                                    &n_calls))\n",
      "00809\t    return NULL;\n",
      "00810\t  int err = 0;\n",
      "00811\t  self->position_of_error = -1;\n",
      "00812\t  // create constants used to fill the var_compute_cells\n",
      "00813\t  PyObject * one = PyInt_FromLong(1);\n",
      "00814\t  PyObject * zero = PyInt_FromLong(0);\n",
      "00815\t\n",
      "00816\t  // pre-allocate our return value\n",
      "00817\t  Py_INCREF(Py_None);\n",
      "00818\t  PyObject * rval = Py_None;\n",
      "00819\t  //clear storage of pre_call_clear elements\n",
      "00820\t  for (int call_i = 0; call_i < n_calls && (!err); ++call_i)\n",
      "00821\t    {\n",
      "00822\t      Py_ssize_t n_pre_call_clear = PyList_Size(self->pre_call_clear);\n",
      "00823\t      assert(PyList_Check(self->pre_call_clear));\n",
      "00824\t      for (int i = 0; i < n_pre_call_clear; ++i)\n",
      "00825\t        {\n",
      "00826\t          PyObject * el_i = PyList_GetItem(self->pre_call_clear, i);\n",
      "00827\t          Py_INCREF(Py_None);\n",
      "00828\t          PyList_SetItem(el_i, 0, Py_None);\n",
      "00829\t        }\n",
      "00830\t      //clear the computed flag out of all non-input vars\n",
      "00831\t      for (int i = 0; i < self->n_vars; ++i)\n",
      "00832\t        {\n",
      "00833\t          self->var_computed[i] = !self->var_has_owner[i];\n",
      "00834\t          if (self->var_computed[i])\n",
      "00835\t            {\n",
      "00836\t              Py_INCREF(one);\n",
      "00837\t              PyList_SetItem(self->var_computed_cells[i], 0, one);\n",
      "00838\t            }\n",
      "00839\t          else\n",
      "00840\t            {\n",
      "00841\t              Py_INCREF(zero);\n",
      "00842\t              PyList_SetItem(self->var_computed_cells[i], 0, zero);\n",
      "00843\t            }\n",
      "00844\t        }\n",
      "00845\t\n",
      "00846\t      for (int i = 0; i < self->n_output_vars && (!err); ++i)\n",
      "00847\t        {\n",
      "00848\t          err = lazy_rec_eval(self, self->output_vars[i], one, zero);\n",
      "00849\t        }\n",
      "00850\t\n",
      "00851\t      if (!err)\n",
      "00852\t        {\n",
      "00853\t          // save references to outputs prior to updating storage containers\n",
      "00854\t          assert (self->n_output_vars >= self->n_updates);\n",
      "00855\t          Py_DECREF(rval);\n",
      "00856\t          rval = PyList_New(self->n_output_vars);\n",
      "00857\t          for (int i = 0; i < (self->n_output_vars); ++i)\n",
      "00858\t            {\n",
      "00859\t              Py_ssize_t src = self->output_vars[i];\n",
      "00860\t              PyObject * item = PyList_GetItem(self->var_value_cells[src], 0);\n",
      "00861\t              if (self->var_computed[src] != 1)\n",
      "00862\t                {\n",
      "00863\t                  err = 1;\n",
      "00864\t                  PyErr_Format(PyExc_AssertionError,\n",
      "00865\t                               \"The compute map of output %d should contain \"\n",
      "00866\t                               \"1 at the end of execution, not %d.\",\n",
      "00867\t                               i, self->var_computed[src]);\n",
      "00868\t                  break;\n",
      "00869\t                }\n",
      "00870\t              Py_INCREF(item);\n",
      "00871\t              PyList_SetItem(rval, i, item);\n",
      "00872\t            }\n",
      "00873\t        }\n",
      "00874\t\n",
      "00875\t      if (!err)\n",
      "00876\t        {\n",
      "00877\t          // Update the inputs that have an update rule\n",
      "00878\t          for (int i = 0; i < self->n_updates; ++i)\n",
      "00879\t            {\n",
      "00880\t              PyObject* tmp = PyList_GetItem(rval, self->n_output_vars - self->n_updates + i);\n",
      "00881\t              Py_INCREF(tmp);\n",
      "00882\t              Py_ssize_t dst = self->update_storage[i];\n",
      "00883\t              PyList_SetItem(self->var_value_cells[dst], 0, tmp);\n",
      "00884\t            }\n",
      "00885\t        }\n",
      "00886\t    }\n",
      "00887\t\n",
      "00888\t  /*\n",
      "00889\t    Clear everything that is left and not an output.  This is needed\n",
      "00890\t    for lazy evaluation since the current GC algo is too conservative\n",
      "00891\t    with lazy graphs.\n",
      "00892\t  */\n",
      "00893\t  if (self->allow_gc && !err)\n",
      "00894\t    {\n",
      "00895\t      for (Py_ssize_t i = 0; i < self->n_vars; ++i)\n",
      "00896\t        {\n",
      "00897\t          int do_cleanup = 1;\n",
      "00898\t          if (!self->var_has_owner[i] || !self->var_computed[i])\n",
      "00899\t            continue;\n",
      "00900\t          for (int j = 0; j < self->n_output_vars; ++j)\n",
      "00901\t            {\n",
      "00902\t              if (i == self->output_vars[j])\n",
      "00903\t                {\n",
      "00904\t                  do_cleanup = 0;\n",
      "00905\t                  break;\n",
      "00906\t                }\n",
      "00907\t            }\n",
      "00908\t          if (!do_cleanup)\n",
      "00909\t            continue;\n",
      "00910\t          Py_INCREF(Py_None);\n",
      "00911\t          PyList_SetItem(self->var_value_cells[i], 0, Py_None);\n",
      "00912\t        }\n",
      "00913\t    }\n",
      "00914\t  Py_DECREF(one);\n",
      "00915\t  Py_DECREF(zero);\n",
      "00916\t  if (err)\n",
      "00917\t    {\n",
      "00918\t      Py_DECREF(rval);\n",
      "00919\t      return NULL;\n",
      "00920\t    }\n",
      "00921\t  return rval;\n",
      "00922\t}\n",
      "00923\t\n",
      "00924\t#if 0\n",
      "00925\tstatic PyMethodDef CLazyLinker_methods[] = {\n",
      "00926\t    {\n",
      "00927\t      //\"name\", (PyCFunction)CLazyLinker_accept, METH_VARARGS, \"Return the name, combining the first and last name\"\n",
      "00928\t    },\n",
      "00929\t    {NULL}  /* Sentinel */\n",
      "00930\t};\n",
      "00931\t#endif\n",
      "00932\t\n",
      "00933\t\n",
      "00934\tstatic PyObject *\n",
      "00935\tCLazyLinker_get_allow_gc(CLazyLinker *self, void *closure)\n",
      "00936\t{\n",
      "00937\t    return PyBool_FromLong(self->allow_gc);\n",
      "00938\t}\n",
      "00939\t\n",
      "00940\tstatic int\n",
      "00941\tCLazyLinker_set_allow_gc(CLazyLinker *self, PyObject *value, void *closure)\n",
      "00942\t{\n",
      "00943\t  if(!PyBool_Check(value))\n",
      "00944\t    return -1;\n",
      "00945\t\n",
      "00946\t  if (value == Py_True)\n",
      "00947\t    self->allow_gc = true;\n",
      "00948\t  else\n",
      "00949\t    self->allow_gc = false;\n",
      "00950\t  return 0;\n",
      "00951\t}\n",
      "00952\t\n",
      "00953\tstatic PyGetSetDef CLazyLinker_getset[] = {\n",
      "00954\t  {(char*)\"allow_gc\",\n",
      "00955\t   (getter)CLazyLinker_get_allow_gc,\n",
      "00956\t   (setter)CLazyLinker_set_allow_gc,\n",
      "00957\t   (char*)\"do this function support allow_gc\",\n",
      "00958\t   NULL},\n",
      "00959\t  {NULL, NULL, NULL, NULL}  /* Sentinel */\n",
      "00960\t};\n",
      "00961\tstatic PyMemberDef CLazyLinker_members[] = {\n",
      "00962\t    {(char*)\"nodes\", T_OBJECT_EX, offsetof(CLazyLinker, nodes), 0,\n",
      "00963\t     (char*)\"list of nodes\"},\n",
      "00964\t    {(char*)\"thunks\", T_OBJECT_EX, offsetof(CLazyLinker, thunks), 0,\n",
      "00965\t     (char*)\"list of thunks in program\"},\n",
      "00966\t    {(char*)\"call_counts\", T_OBJECT_EX, offsetof(CLazyLinker, call_counts), 0,\n",
      "00967\t     (char*)\"number of calls of each thunk\"},\n",
      "00968\t    {(char*)\"call_times\", T_OBJECT_EX, offsetof(CLazyLinker, call_times), 0,\n",
      "00969\t     (char*)\"total runtime in each thunk\"},\n",
      "00970\t    {(char*)\"position_of_error\", T_INT, offsetof(CLazyLinker, position_of_error), 0,\n",
      "00971\t     (char*)\"position of failed thunk\"},\n",
      "00972\t    {(char*)\"time_thunks\", T_INT, offsetof(CLazyLinker, do_timing), 0,\n",
      "00973\t     (char*)\"bool: nonzero means call will time thunks\"},\n",
      "00974\t    {(char*)\"need_update_inputs\", T_INT, offsetof(CLazyLinker, need_update_inputs), 0,\n",
      "00975\t     (char*)\"bool: nonzero means Function.__call__ must implement update mechanism\"},\n",
      "00976\t    {NULL}  /* Sentinel */\n",
      "00977\t};\n",
      "00978\t\n",
      "00979\tstatic PyTypeObject lazylinker_ext_CLazyLinkerType = {\n",
      "00980\t#if defined(NPY_PY3K)\n",
      "00981\t    PyVarObject_HEAD_INIT(NULL, 0)\n",
      "00982\t#else\n",
      "00983\t    PyObject_HEAD_INIT(NULL)\n",
      "00984\t    0,                         /*ob_size*/\n",
      "00985\t#endif\n",
      "00986\t    \"lazylinker_ext.CLazyLinker\",             /*tp_name*/\n",
      "00987\t    sizeof(CLazyLinker), /*tp_basicsize*/\n",
      "00988\t    0,                         /*tp_itemsize*/\n",
      "00989\t    CLazyLinker_dealloc,       /*tp_dealloc*/\n",
      "00990\t    0,                         /*tp_print*/\n",
      "00991\t    0,                         /*tp_getattr*/\n",
      "00992\t    0,                         /*tp_setattr*/\n",
      "00993\t    0,                         /*tp_compare*/\n",
      "00994\t    0,                         /*tp_repr*/\n",
      "00995\t    0,                         /*tp_as_number*/\n",
      "00996\t    0,                         /*tp_as_sequence*/\n",
      "00997\t    0,                         /*tp_as_mapping*/\n",
      "00998\t    0,                         /*tp_hash */\n",
      "00999\t    CLazyLinker_call,          /*tp_call*/\n",
      "01000\t    0,                         /*tp_str*/\n",
      "01001\t    0,                         /*tp_getattro*/\n",
      "01002\t    0,                         /*tp_setattro*/\n",
      "01003\t    0,                         /*tp_as_buffer*/\n",
      "01004\t    Py_TPFLAGS_DEFAULT|Py_TPFLAGS_BASETYPE,        /*tp_flags*/\n",
      "01005\t    \"CLazyLinker object\",      /* tp_doc */\n",
      "01006\t    0,                         /* tp_traverse */\n",
      "01007\t    0,                         /* tp_clear */\n",
      "01008\t    0,                         /* tp_richcompare */\n",
      "01009\t    0,                         /* tp_weaklistoffset */\n",
      "01010\t    0,                         /* tp_iter */\n",
      "01011\t    0,                         /* tp_iternext */\n",
      "01012\t    0,//CLazyLinker_methods,       /* tp_methods */\n",
      "01013\t    CLazyLinker_members,       /* tp_members */\n",
      "01014\t    CLazyLinker_getset,        /* tp_getset */\n",
      "01015\t    0,                         /* tp_base */\n",
      "01016\t    0,                         /* tp_dict */\n",
      "01017\t    0,                         /* tp_descr_get */\n",
      "01018\t    0,                         /* tp_descr_set */\n",
      "01019\t    0,                         /* tp_dictoffset */\n",
      "01020\t    (initproc)CLazyLinker_init,/* tp_init */\n",
      "01021\t    0,                         /* tp_alloc */\n",
      "01022\t    CLazyLinker_new,           /* tp_new */\n",
      "01023\t};\n",
      "01024\t\n",
      "01025\tstatic PyObject * get_version(PyObject *dummy, PyObject *args)\n",
      "01026\t{\n",
      "01027\t  PyObject *result = PyFloat_FromDouble(0.21);\n",
      "01028\t  return result;\n",
      "01029\t}\n",
      "01030\t\n",
      "01031\tstatic PyMethodDef lazylinker_ext_methods[] = {\n",
      "01032\t  {\"get_version\",  get_version, METH_VARARGS, \"Get extension version.\"},\n",
      "01033\t  {NULL, NULL, 0, NULL}        /* Sentinel */\n",
      "01034\t};\n",
      "01035\t\n",
      "01036\t#ifndef PyMODINIT_FUNC  /* declarations for DLL import/export */\n",
      "01037\t#define PyMODINIT_FUNC void\n",
      "01038\t#endif\n",
      "01039\t\n",
      "01040\t#if defined(NPY_PY3K)\n",
      "01041\tstatic struct PyModuleDef moduledef = {\n",
      "01042\t        PyModuleDef_HEAD_INIT,\n",
      "01043\t        \"lazylinker_ext\",\n",
      "01044\t        NULL,\n",
      "01045\t        -1,\n",
      "01046\t        lazylinker_ext_methods,\n",
      "01047\t        NULL,\n",
      "01048\t        NULL,\n",
      "01049\t        NULL,\n",
      "01050\t        NULL\n",
      "01051\t};\n",
      "01052\t#endif\n",
      "01053\t#if defined(NPY_PY3K)\n",
      "01054\t#define RETVAL m\n",
      "01055\tPyMODINIT_FUNC\n",
      "01056\tPyInit_lazylinker_ext(void) {\n",
      "01057\t#else\n",
      "01058\t#define RETVAL\n",
      "01059\tPyMODINIT_FUNC\n",
      "01060\tinitlazylinker_ext(void) \n",
      "01061\t{\n",
      "01062\t#endif\n",
      "01063\t    PyObject* m;\n",
      "01064\t\n",
      "01065\t    lazylinker_ext_CLazyLinkerType.tp_new = PyType_GenericNew;\n",
      "01066\t    if (PyType_Ready(&lazylinker_ext_CLazyLinkerType) < 0)\n",
      "01067\t        return RETVAL;\n",
      "01068\t#if defined(NPY_PY3K)\n",
      "01069\t    m = PyModule_Create(&moduledef);\n",
      "01070\t#else\n",
      "01071\t    m = Py_InitModule3(\"lazylinker_ext\", lazylinker_ext_methods,\n",
      "01072\t                       \"Example module that creates an extension type.\");\n",
      "01073\t#endif\n",
      "01074\t    Py_INCREF(&lazylinker_ext_CLazyLinkerType);\n",
      "01075\t    PyModule_AddObject(m, \"CLazyLinker\", (PyObject *)&lazylinker_ext_CLazyLinkerType);\n",
      "01076\t\n",
      "01077\t    return RETVAL;\n",
      "01078\t}\n",
      "01079\t\n",
      "01080\t\n",
      "Problem occurred during compilation with the command line below:\n",
      "g++ -shared -g -D NPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION -m32 -IC:\\Anaconda\\lib\\site-packages\\numpy\\core\\include -IC:\\Anaconda\\include -o C:\\Users\\trtrmitya\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_69_Stepping_1_GenuineIntel-2.7.9-32\\lazylinker_ext\\lazylinker_ext.pyd C:\\Users\\trtrmitya\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_69_Stepping_1_GenuineIntel-2.7.9-32\\lazylinker_ext\\mod.cpp -LC:\\Anaconda\\libs -LC:\\Anaconda -lpython27\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Compilation failed (return status=1): 'g++' is not recognized as an internal or external command,\r. operable program or batch file.\r. ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cfd2f29f29cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Take a moment to install Theano.  We will use it for building neural networks.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msandbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrng_mrg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMRG_RandomStreams\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mRandomStreams\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\__init__.pyc\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mobject2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m \u001b[1;32mimport\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mSymbolicInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mSymbolicOutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOut\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\compile\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         SpecifyShape, specify_shape, register_specify_shape_c_code)\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_module\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgof\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython2x\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m from theano.compile.io import (\n\u001b[0;32m     20\u001b[0m     In, SymbolicInput, SymbolicInputKit, SymbolicOutput)\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\compile\\mode.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m  \u001b[0mtheano\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgof\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfigparser\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAddConfigVar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStrParam\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_view_op_c_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_output_guard\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\gof\\vm.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mlazylinker_c\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mCVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlazylinker_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLazyLinker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\gof\\lazylinker_c.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGCC_compiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             cmodule.GCC_compiler.compile_str(dirname, code, location=loc,\n\u001b[1;32m--> 116\u001b[1;33m                                              preargs=args)\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[1;31m# Save version into the __init__.py file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0minit_py\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__init__.py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\gof\\cmodule.pyc\u001b[0m in \u001b[0;36mcompile_str\u001b[1;34m(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module)\u001b[0m\n\u001b[0;32m   2008\u001b[0m             \u001b[1;31m# difficult to read.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m             raise Exception('Compilation failed (return status=%s): %s' %\n\u001b[1;32m-> 2010\u001b[1;33m                             (status, compile_stderr.replace('\\n', '. ')))\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompilation_warning\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcompile_stderr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m             \u001b[1;31m# Print errors just below the command line.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Compilation failed (return status=1): 'g++' is not recognized as an internal or external command,\r. operable program or batch file.\r. "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Familiar libraries.\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "\n",
    "# Take a moment to install Theano.  We will use it for building neural networks.\n",
    "import theano \n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "print theano.config.device # We're using CPUs (for now)\n",
    "print theano.config.floatX # Should be 64 bit for CPUs\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features = 784\n",
      "Train set = 2000\n",
      "Test set = 2000\n"
     ]
    }
   ],
   "source": [
    "# Repeating steps from Project 1 to prepare mnist dataset. \n",
    "mnist = fetch_mldata('MNIST original', data_home='~/datasets/mnist')\n",
    "X, Y = mnist.data, mnist.target\n",
    "X = X / 255.0\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "numExamples = 2000\n",
    "test_data, test_labels = X[70000-numExamples:], Y[70000-numExamples:]\n",
    "train_data, train_labels = X[:numExamples], Y[:numExamples]\n",
    "numFeatures = train_data[1].size\n",
    "numTrainExamples = train_data.shape[0]\n",
    "numTestExamples = test_data.shape[0]\n",
    "print 'Features = %d' %(numFeatures)\n",
    "print 'Train set = %d' %(numTrainExamples)\n",
    "print 'Test set = %d' %(numTestExamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes = 10\n"
     ]
    }
   ],
   "source": [
    "# Convert labels into a set of binary variables, one for each class (sometimes called a 1-of-n encoding).  \n",
    "# This makes working with NNs easier: there will be one output node for each class.\n",
    "def binarizeY(data):\n",
    "    binarized_data = np.zeros((data.size,10))\n",
    "    for j in range(0,data.size):\n",
    "        feature = data[j:j+1]\n",
    "        i = feature.astype(np.int64) \n",
    "        binarized_data[j,i]=1\n",
    "    return binarized_data\n",
    "train_labels_b = binarizeY(train_labels)\n",
    "test_labels_b = binarizeY(test_labels)\n",
    "numClasses = train_labels_b[1].size\n",
    "print 'Classes = %d' %(numClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time = 0.09\n",
      "Accuracy = 0.9025\n",
      "Prediction time = 6.58\n"
     ]
    }
   ],
   "source": [
    "# Lets start with a simple KNN model to establish a baseline accuracy.\n",
    "# Question: You've seen a number of different machine learning algos.  What's your intuition about KNN scaling and \n",
    "# accuracy characteristics vs. other algos? \n",
    "neighbors = 1\n",
    " # we'll be waiting quite a while if we use 60K\n",
    "knn = KNeighborsClassifier(neighbors)\n",
    "mini_train_data, mini_train_labels = X[:numExamples], Y[:numExamples] \n",
    "start_time = time.time()\n",
    "knn.fit(mini_train_data, mini_train_labels)\n",
    "print 'Train time = %.2f' %(time.time() - start_time)\n",
    "start_time = time.time()\n",
    "accuracy = knn.score(test_data, test_labels)\n",
    "print 'Accuracy = %.4f' %(accuracy)\n",
    "print 'Prediction time = %.2f' %(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name gof",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-892120bb945a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# We'll start in Theano with implententing logistic regression.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Recall the four key components: (1) parms, (2) model, (3) cost, and (4) objective.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m## (1) Parms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Init weights to small, but non-zero, values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mobject2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m \u001b[1;32mimport\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mSymbolicInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mSymbolicOutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOut\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\compile\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         SpecifyShape, specify_shape, register_specify_shape_c_code)\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_module\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgof\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython2x\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name gof"
     ]
    }
   ],
   "source": [
    "# We'll start in Theano with implententing logistic regression.  \n",
    "# Recall the four key components: (1) parms, (2) model, (3) cost, and (4) objective. \n",
    "import theano\n",
    "## (1) Parms \n",
    "# Init weights to small, but non-zero, values.\n",
    "w = theano.shared(np.asarray((np.random.randn(*(numFeatures, numClasses))*.01)))\n",
    "\n",
    "## (2) Model\n",
    "# Theano objects accessed with standard Python variables\n",
    "X = T.matrix()\n",
    "Y = T.matrix()\n",
    "# Two things to note here.\n",
    "# First, logistic regression can be thought of as a neural net with no hidden layers.  So the output values are \n",
    "# just the dot product of the inputs and the edge weights.\n",
    "# Second, we have 10 classes.  So we can either train separate 1 vs all classification using sigmoid activation, \n",
    "# which would be a hassle, or we can use the softmax activation, which is essentially a multi-class version of sigmoid. \n",
    "\n",
    "def model(X, w):\n",
    "    return T.nnet.softmax(T.dot(X, w))\n",
    "y_hat = model(X, w)\n",
    "\n",
    "## (3) Cost\n",
    "# Cross entropy only considers the error between the true class and the prediction, and not the errors for the false \n",
    "# classes.  This tends to cause the network to converge faster.\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat, Y))\n",
    "\n",
    "## (4) Objective\n",
    "# Minimization using gradient descent.\n",
    "alpha = 0.01\n",
    "gradient = T.grad(cost=cost, wrt=w)\n",
    "update = [[w, w - gradient * alpha]] \n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True) # computes cost, then runs update\n",
    "y_pred = T.argmax(y_hat, axis=1) # select largest probability as prediction\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "def gradientDescent(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    for i in range(epochs):\n",
    "        start_time = time.time()\n",
    "        cost = train(train_data[0:len(train_data)], train_labels_b[0:len(train_data)])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print '%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(test_labels_b, axis=1) == predict(test_data)))\n",
    "    print 'train time = %.2f' %(trainTime)\n",
    "\n",
    "gradientDescent(50)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(test_data)   \n",
    "print 'predict time = %.2f' %(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) accuracy = 0.8445\n",
      "2) accuracy = 0.8640\n",
      "3) accuracy = 0.8710\n",
      "4) accuracy = 0.8720\n",
      "5) accuracy = 0.8705\n",
      "6) accuracy = 0.8695\n",
      "7) accuracy = 0.8695\n",
      "8) accuracy = 0.8685\n",
      "9) accuracy = 0.8705\n",
      "10) accuracy = 0.8715\n",
      "train time = 7.91\n",
      "predict time = 0.00\n"
     ]
    }
   ],
   "source": [
    "## Let's switch to SGD and observe the impact. \n",
    "\n",
    "## (1) Parms\n",
    "w = theano.shared(np.asarray((np.random.randn(*(numFeatures, numClasses))*.01)))\n",
    "\n",
    "## (2) Model\n",
    "X = T.matrix()\n",
    "Y = T.matrix()\n",
    "def model(X, w):\n",
    "    return T.nnet.softmax(T.dot(X, w))\n",
    "y_hat = model(X, w)\n",
    "\n",
    "## (3) Cost\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat, Y))\n",
    "\n",
    "## (4) Objective\n",
    "alpha = 0.01\n",
    "gradient = T.grad(cost=cost, wrt=w)\n",
    "update = [[w, w - gradient * alpha]] \n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True) \n",
    "y_pred = T.argmax(y_hat, axis=1) \n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "## Play with this value and notice the impact.\n",
    "miniBatchSize = 1 \n",
    "def gradientDescentStochastic(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    start_time = time.time()\n",
    "    for i in range(epochs):       \n",
    "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
    "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print '%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(test_labels_b, axis=1) == predict(test_data)))     \n",
    "    print 'train time = %.2f' %(trainTime)\n",
    "    \n",
    "gradientDescentStochastic(10)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(test_data)   \n",
    "print 'predict time = %.2f' %(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) accuracy = 0.2505\n",
      "2) accuracy = 0.6845\n",
      "3) accuracy = 0.7795\n",
      "4) accuracy = 0.8170\n",
      "5) accuracy = 0.8370\n",
      "6) accuracy = 0.8535\n",
      "7) accuracy = 0.8625\n",
      "8) accuracy = 0.8645\n",
      "9) accuracy = 0.8655\n",
      "10) accuracy = 0.8680\n",
      "train time = 140.46\n",
      "predict time = 0.07\n"
     ]
    }
   ],
   "source": [
    "## Now let's add a hidden layer (two layer neural net).\n",
    "\n",
    "## (1) Parms\n",
    "# Try playing with this value.\n",
    "numHiddenNodes = 600 \n",
    "w_1 = theano.shared(np.asarray((np.random.randn(*(numFeatures, numHiddenNodes))*.01)))\n",
    "w_2 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numClasses))*.01)))\n",
    "params = [w_1, w_2]\n",
    "\n",
    "\n",
    "## (2) Model\n",
    "X = T.matrix()\n",
    "Y = T.matrix()\n",
    "# Two notes:\n",
    "# First, feed forward is the composition of layers (dot product + activation function)\n",
    "# Second, activation on the hidden layer still uses sigmoid\n",
    "def model(X, w_1, w_2):\n",
    "    return T.nnet.softmax(T.dot(T.nnet.sigmoid(T.dot(X, w_1)), w_2))\n",
    "y_hat = model(X, w_1, w_2)\n",
    "\n",
    "\n",
    "## (3) Cost...same as logistic regression\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat, Y))\n",
    "\n",
    "\n",
    "## (4) Minimization.  Update rule changes to backpropagation.\n",
    "alpha = 0.01\n",
    "def backprop(cost, w):\n",
    "    grads = T.grad(cost=cost, wrt=w)\n",
    "    updates = []\n",
    "    for w1, grad in zip(w, grads):\n",
    "        updates.append([w1, w1 - grad * alpha])\n",
    "    return updates\n",
    "update = backprop(cost, params)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
    "y_pred = T.argmax(y_hat, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "miniBatchSize = 1 \n",
    "def gradientDescentStochastic(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    start_time = time.time()\n",
    "    for i in range(epochs):\n",
    "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
    "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print '%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(test_labels_b, axis=1) == predict(test_data)))\n",
    "    print 'train time = %.2f' %(trainTime)\n",
    "\n",
    "gradientDescentStochastic(10)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(test_data)   \n",
    "print 'predict time = %.2f' %(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 2: Ideas from 2010 onward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As interest in bigger and deeper networks has increased, a couple of tricks have emerged and become standard practice.  Let's look at two of those--rectifier activation and dropout noise--that we'll use with deep networks.\n",
    "\n",
    "For a more in-depth examination of the topic, check out this 1-day tutorial from KDD2014:\n",
    "\n",
    "Part 1: http://videolectures.net/kdd2014_bengio_deep_learning/\n",
    "\n",
    "Part 2: http://videolectures.net/tcmm2014_taylor_deep_learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) accuracy = 0.1045\n",
      "2) accuracy = 0.1045\n",
      "3) accuracy = 0.1045\n",
      "4) accuracy = 0.1045\n",
      "5) accuracy = 0.1045\n",
      "6) accuracy = 0.1045\n",
      "7) accuracy = 0.1045\n",
      "8) accuracy = 0.1045\n",
      "9) accuracy = 0.1045\n",
      "10) accuracy = 0.1630\n",
      "train time = 300.86\n",
      "predict time = 0.13\n"
     ]
    }
   ],
   "source": [
    "## A curiousity: what happens if we simply add a third layer?\n",
    "\n",
    "## (1) Parms\n",
    "numHiddenNodes = 600 \n",
    "w_1 = theano.shared(np.asarray((np.random.randn(*(numFeatures, numHiddenNodes))*.01)))\n",
    "w_2 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numHiddenNodes))*.01)))\n",
    "w_3 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numClasses))*.01)))\n",
    "params = [w_1, w_2, w_3]\n",
    "\n",
    "## (2) Model\n",
    "X = T.matrix()\n",
    "Y = T.matrix()\n",
    "def model(X, w_1, w_2, w_3):\n",
    "    return T.nnet.softmax(T.dot(T.nnet.sigmoid(T.dot(T.nnet.sigmoid(T.dot(X, w_1)), w_2)), w_3))\n",
    "y_hat = model(X, w_1, w_2, w_3)\n",
    "\n",
    "\n",
    "## (3) Cost...same as logistic regression\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat, Y))\n",
    "\n",
    "\n",
    "## (4) Minimization.  Update rule changes to backpropagation.\n",
    "alpha = 0.01\n",
    "def backprop(cost, w):\n",
    "    grads = T.grad(cost=cost, wrt=w)\n",
    "    updates = []\n",
    "    for w1, grad in zip(w, grads):\n",
    "        updates.append([w1, w1 - grad * alpha])\n",
    "    return updates\n",
    "update = backprop(cost, params)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
    "y_pred = T.argmax(y_hat, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "miniBatchSize = 1 \n",
    "def gradientDescentStochastic(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    start_time = time.time()\n",
    "    for i in range(epochs):\n",
    "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
    "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print '%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(test_labels_b, axis=1) == predict(test_data)))\n",
    "    print 'train time = %.2f' %(trainTime)\n",
    "\n",
    "gradientDescentStochastic(10)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(test_data)   \n",
    "print 'predict time = %.2f' %(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Revisted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we revisit adding layers, let's look at a recent idea around activation closely associated with deep learning.  In 2010, in a paper published at NIPS (https://www.utc.fr/~bordesan/dokuwiki/_media/en/glorot10nipsworkshop.pdf), Yoshua Bengio showed that rectifier activation works better empirically than sigmoid activation when used in the hidden layers.  \n",
    "\n",
    "The rectifier activation is simple: f(x)=max(0,x).  Intuitively, the difference is that as a sigmoid activated node approaches 1 it stops learning even if error continues to be propagated to it, whereas the rectifier activated node continue to learn (at least in the positive direction).  It is not completely understood (per Yoshua Bengio) why this helps, but there are some theories being explored including as related to the benefits of sparse representations in networks. (http://www.iro.umontreal.ca/~bengioy/talks/KDD2014-tutorial.pdf).  Rectifiers also speed up training.\n",
    "\n",
    "Although the paper was published in 2010, the technique didn't gain widespread adoption until 2012 when members of Hinton's group spread the word, including with this Kaggle entry: http://blog.kaggle.com/2012/11/01/deep-learning-how-i-did-it-merck-1st-place-interview/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) accuracy = 0.8220\n",
      "2) accuracy = 0.8615\n",
      "3) accuracy = 0.8720\n",
      "4) accuracy = 0.8755\n",
      "5) accuracy = 0.8810\n",
      "6) accuracy = 0.8840\n",
      "7) accuracy = 0.8930\n",
      "8) accuracy = 0.8980\n",
      "9) accuracy = 0.9015\n",
      "10) accuracy = 0.9020\n",
      "train time = 130.99\n",
      "predict time = 0.07\n"
     ]
    }
   ],
   "source": [
    "## 2-layer NN with rectify activation on the hidden layer.\n",
    "\n",
    "## (1) Parms\n",
    "numHiddenNodes = 600 \n",
    "w_1 = theano.shared(np.asarray((np.random.randn(*(numFeatures, numHiddenNodes))*.01)))\n",
    "w_2 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numClasses))*.01)))\n",
    "params = [w_1, w_2]\n",
    "\n",
    "\n",
    "## (2) Model\n",
    "X = T.matrix()\n",
    "Y = T.matrix()\n",
    "\n",
    "def model(X, w_1, w_2):\n",
    "    return T.nnet.softmax(T.dot(T.maximum(T.dot(X, w_1), 0.), w_2))\n",
    "y_hat = model(X, w_1, w_2)\n",
    "\n",
    "\n",
    "## (3) Cost...same as logistic regression\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat, Y))\n",
    "\n",
    "\n",
    "## (4) Minimization.  Update rule changes to backpropagation.\n",
    "alpha = 0.01\n",
    "def backprop(cost, w):\n",
    "    grads = T.grad(cost=cost, wrt=w)\n",
    "    updates = []\n",
    "    for w1, grad in zip(w, grads):\n",
    "        updates.append([w1, w1 - grad * alpha])\n",
    "    return updates\n",
    "update = backprop(cost, params)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
    "y_pred = T.argmax(y_hat, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "miniBatchSize = 1 \n",
    "def gradientDescentStochastic(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    start_time = time.time()\n",
    "    for i in range(epochs):\n",
    "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
    "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print '%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(test_labels_b, axis=1) == predict(test_data)))\n",
    "    print 'train time = %.2f' %(trainTime)\n",
    "\n",
    "gradientDescentStochastic(10)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(test_data)   \n",
    "print 'predict time = %.2f' %(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maxout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an exercise, switch to Maxout (or Max Pooling) activiation.  Maxout activation just selects the max input as the output.  Maxout is a type of pooling, a technique which performs particularly well for vision problems. (http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf, http://www.quora.com/What-is-impact-of-different-pooling-methods-in-convolutional-neural-networks).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second trick closely associated with deep learning, and that is now commonplace, is called 'Dropouts'.  The idea is that instead of (or in addition to) adding noise to our inputs, we add noise by having each node return 0 with a certain probability during training.  This trick both improves generalization in large networks and speeds up training.\n",
    "\n",
    "Hinton introduced the idea in 2012 and gave an explanation of why it's similar to bagging (http://arxiv.org/pdf/1207.0580v1.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) accuracy = 0.8160\n",
      "2) accuracy = 0.8530\n",
      "3) accuracy = 0.8775\n",
      "4) accuracy = 0.8840\n",
      "5) accuracy = 0.8725\n",
      "6) accuracy = 0.8975\n",
      "7) accuracy = 0.8985\n",
      "8) accuracy = 0.9035\n",
      "9) accuracy = 0.9090\n",
      "10) accuracy = 0.9140\n",
      "train time = 156.16\n",
      "predict time = 0.06\n"
     ]
    }
   ],
   "source": [
    "# Dropouts\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "\n",
    "## (1) Parms\n",
    "numHiddenNodes = 600 \n",
    "w_1 = theano.shared(np.asarray((np.random.randn(*(numFeatures, numHiddenNodes))*.01)))\n",
    "w_2 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numClasses))*.01)))\n",
    "params = [w_1, w_2]\n",
    "\n",
    "\n",
    "## (2) Model\n",
    "X = T.matrix()\n",
    "Y = T.matrix()\n",
    "srng = RandomStreams()\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        X *= srng.binomial(X.shape, p=1 - p)\n",
    "        X /= 1 - p\n",
    "    return X\n",
    "\n",
    "def model(X, w_1, w_2, p_1, p_2):\n",
    "    return T.nnet.softmax(T.dot(dropout(T.maximum(T.dot(dropout(X, p_1), w_1),0.), p_2), w_2))\n",
    "\n",
    "y_hat_train = model(X, w_1, w_2, 0.2, 0.5)\n",
    "y_hat_predict = model(X, w_1, w_2, 0., 0.)\n",
    "\n",
    "## (3) Cost...same as logistic regression\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat_train, Y))\n",
    "\n",
    "## (4) Minimization.  Update rule changes to backpropagation.\n",
    "alpha = 0.01\n",
    "def backprop(cost, w):\n",
    "    grads = T.grad(cost=cost, wrt=w)\n",
    "    updates = []\n",
    "    for w1, grad in zip(w, grads):\n",
    "        updates.append([w1, w1 - grad * alpha])\n",
    "    return updates\n",
    "update = backprop(cost, params)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
    "y_pred = T.argmax(y_hat_predict, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "\n",
    "miniBatchSize = 1\n",
    "def gradientDescentStochastic(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    start_time = time.time()\n",
    "    for i in range(epochs):\n",
    "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
    "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print '%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(test_labels_b, axis=1) == predict(test_data)))\n",
    "    print 'train time = %.2f' %(trainTime)\n",
    "\n",
    "gradientDescentStochastic(10)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(test_data)   \n",
    "print 'predict time = %.2f' %(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) accuracy = 0.6045\n",
      "2) accuracy = 0.7655\n",
      "3) accuracy = 0.8645\n",
      "4) accuracy = 0.8720\n",
      "5) accuracy = 0.8865\n",
      "6) accuracy = 0.8935\n",
      "7) accuracy = 0.8975\n",
      "8) accuracy = 0.9065\n",
      "9) accuracy = 0.9155\n",
      "10) accuracy = 0.9070\n",
      "train time = 322.41\n",
      "predict time = 0.10\n"
     ]
    }
   ],
   "source": [
    "# Let's add back in that third layer\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "\n",
    "## (1) Parms\n",
    "numHiddenNodes = 600 \n",
    "w_1 = theano.shared(np.asarray((np.random.randn(*(numFeatures, numHiddenNodes))*.01)))\n",
    "w_2 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numHiddenNodes))*.01)))\n",
    "w_3 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numClasses))*.01)))\n",
    "params = [w_1, w_2, w_3]\n",
    "\n",
    "\n",
    "## (2) Model\n",
    "X = T.matrix()\n",
    "Y = T.matrix()\n",
    "\n",
    "srng = RandomStreams()\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        X *= srng.binomial(X.shape, p=1 - p)\n",
    "        X /= 1 - p\n",
    "    return X\n",
    "\n",
    "def model(X, w_1, w_2, w_3, p_1, p_2, p_3):\n",
    "    return T.nnet.softmax(T.dot(dropout(T.maximum(T.dot(dropout(T.maximum(T.dot(dropout(X, p_1), w_1),0.), p_2), w_2),0.), p_3), w_3))\n",
    "\n",
    "y_hat_train = model(X, w_1, w_2, w_3, 0.2, 0.5,0.5)\n",
    "y_hat_predict = model(X, w_1, w_2, w_3, 0., 0.,0.)\n",
    "\n",
    "## (3) Cost...same as logistic regression\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat_train, Y))\n",
    "\n",
    "\n",
    "## (4) Minimization.  Update rule changes to backpropagation.\n",
    "alpha = 0.01\n",
    "def backprop(cost, w):\n",
    "    grads = T.grad(cost=cost, wrt=w)\n",
    "    updates = []\n",
    "    for w1, grad in zip(w, grads):\n",
    "        updates.append([w1, w1 - grad * alpha])\n",
    "    return updates\n",
    "update = backprop(cost, params)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
    "y_pred = T.argmax(y_hat_predict, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "miniBatchSize = 1\n",
    "def gradientDescentStochastic(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    start_time = time.time()\n",
    "    for i in range(epochs):\n",
    "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
    "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print '%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(test_labels_b, axis=1) == predict(test_data)))\n",
    "    print 'train time = %.2f' %(trainTime)\n",
    "\n",
    "gradientDescentStochastic(10)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(test_data)   \n",
    "print 'predict time = %.2f' %(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Convolutional Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, when the phrase 'deep learning' is used to describe a system, it most likely is a convolution net (or convonet).  The convonet architechture was largely developed in the late 90's at Bell Labs, but only very recently popularized.  It was developed for image recognition, and is described and implemented with 2d representations in mind.\n",
    "\n",
    "Geoffrey Hinton has an excellent two-part lecture on the topic:\n",
    "\n",
    "https://www.youtube.com/watch?v=6oD3t6u5EPs\n",
    "\n",
    "https://www.youtube.com/watch?v=fueIAeAsGzA\n",
    "\n",
    "Also, this code was partly taken from these tutorials, which are worth referring back to:\n",
    "\n",
    "http://deeplearning.net/tutorial/lenet.html\n",
    "\n",
    "http://ufldl.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/\n",
    "\n",
    "https://www.youtube.com/watch?v=S75EdAcXHKk\n",
    "\n",
    "http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) accuracy = 0.7460\n",
      "2) accuracy = 0.8870\n",
      "3) accuracy = 0.9315\n",
      "4) accuracy = 0.9535"
     ]
    }
   ],
   "source": [
    "# Let's add back in that third layer\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "from theano.tensor.signal.downsample import max_pool_2d\n",
    "\n",
    "## (1) Parms\n",
    "numHiddenNodes = 600 \n",
    "patchWidth = 3\n",
    "patchHeight = 3\n",
    "featureMapsLayer1 = 32\n",
    "featureMapsLayer2 = 64\n",
    "featureMapsLayer3 = 128\n",
    "\n",
    "# For convonets, we will work in 2d rather than 1d.  The MNIST images are 28x28 in 2d.\n",
    "imageWidth = 28\n",
    "train_data = train_data.reshape(-1, 1, imageWidth, imageWidth)\n",
    "test_data = test_data.reshape(-1, 1, imageWidth, imageWidth)\n",
    "\n",
    "# Convolution layers.  \n",
    "w_1 = theano.shared(np.asarray((np.random.randn(*(featureMapsLayer1, 1, patchWidth, patchHeight))*.01)))\n",
    "w_2 = theano.shared(np.asarray((np.random.randn(*(featureMapsLayer2, featureMapsLayer1, patchWidth, patchHeight))*.01)))\n",
    "w_3 = theano.shared(np.asarray((np.random.randn(*(featureMapsLayer3, featureMapsLayer2, patchWidth, patchHeight))*.01)))\n",
    "\n",
    "# Fully connected NN. \n",
    "w_4 = theano.shared(np.asarray((np.random.randn(*(featureMapsLayer3 * 3 * 3, numHiddenNodes))*.01)))\n",
    "w_5 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numClasses))*.01)))\n",
    "params = [w_1, w_2, w_3, w_4, w_5]\n",
    "\n",
    "## (2) Model\n",
    "X = T.tensor4() # conv2d works with tensor4 type\n",
    "Y = T.matrix()\n",
    "\n",
    "srng = RandomStreams()\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        X *= srng.binomial(X.shape, p=1 - p)\n",
    "        X /= 1 - p\n",
    "    return X\n",
    "\n",
    "# Theano provides built-in support for add convolutional layers\n",
    "def model(X, w_1, w_2, w_3, w_4, w_5, p_1, p_2):\n",
    "    l1 = dropout(max_pool_2d(T.maximum(conv2d(X, w_1, border_mode='full'),0.), (2, 2)), p_1)\n",
    "    l2 = dropout(max_pool_2d(T.maximum(conv2d(l1, w_2), 0.), (2, 2)), p_1)\n",
    "    l3 = dropout(T.flatten(max_pool_2d(T.maximum(conv2d(l2, w_3), 0.), (2, 2)), outdim=2), p_1) # flatten to switch back to 1d layers\n",
    "    l4 = dropout(T.maximum(T.dot(l3, w_4), 0.), p_2)\n",
    "    return T.nnet.softmax(T.dot(l4, w_5))\n",
    "\n",
    "y_hat_train = model(X, w_1, w_2, w_3, w_4, w_5, 0.2, 0.5)\n",
    "y_hat_predict = model(X, w_1, w_2, w_3, w_4, w_5, 0., 0.)\n",
    "y_x = T.argmax(y_hat, axis=1)\n",
    "\n",
    "## (3) Cost\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat_train, Y))\n",
    "\n",
    "## (4) Minimization.  \n",
    "def backprop(cost, w, alpha=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=w)\n",
    "    updates = []\n",
    "    for w1, grad in zip(w, grads):\n",
    "        \n",
    "        # adding gradient scaling\n",
    "        acc = theano.shared(w1.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * grad ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        grad = grad / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        \n",
    "        updates.append((w1, w1 - grad * alpha))\n",
    "    return updates\n",
    "\n",
    "update = backprop(cost, params)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
    "y_pred = T.argmax(y_hat_predict, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "miniBatchSize = 1\n",
    "def gradientDescentStochastic(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    start_time = time.time()\n",
    "    for i in range(epochs):\n",
    "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
    "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print '%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(test_labels_b, axis=1) == predict(test_data)))\n",
    "    print 'train time = %.2f' %(trainTime)\n",
    "\n",
    "gradientDescentStochastic(10)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(test_data)   \n",
    "print 'predict time = %.2f' %(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brain inspiration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architechture of the convonet was inspired by the visual cortext in the human brain.  If you are interested in learning more, check out: http://www-psych.stanford.edu/~ashas/Cognition%20Textbook/chapter2.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self-Driving Vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CES 2015 parts 6,7,9\n",
    "\n",
    "https://www.youtube.com/watch?v=-vKGkxeflGw\n",
    "\n",
    "https://www.youtube.com/watch?v=zsVsUvx8ieo\n",
    "\n",
    "https://www.youtube.com/watch?v=RvQVyGOynFY\n",
    "\n",
    "GTC 2015 parts 4,5,7,9\n",
    "\n",
    "https://www.youtube.com/watch?v=pqvdZ2jp1NA\n",
    "\n",
    "https://www.youtube.com/watch?v=GGxdP_JWhwI\n",
    "\n",
    "https://www.youtube.com/watch?v=Tb7ZYSTYHbw\n",
    "\n",
    "https://www.youtube.com/watch?v=TDm6Snkle70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
